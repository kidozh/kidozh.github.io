<!DOCTYPE html>




<html class="theme-next pisces" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="kidozh的一些想法和随手笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="kidozh">
<meta property="og:url" content="https://kidozh.github.io/index.html">
<meta property="og:site_name" content="kidozh">
<meta property="og:description" content="kidozh的一些想法和随手笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kidozh">
<meta name="twitter:description" content="kidozh的一些想法和随手笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://kidozh.github.io/"/>





  <title>kidozh</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">kidozh</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">某不科学的kidozh</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2018/10/21/Ubuntu下网易云音乐无法打开/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/21/Ubuntu下网易云音乐无法打开/" itemprop="url">解决Ubuntu下网易云音乐无法打开</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-21T14:37:07+08:00">
                2018-10-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>来源： <a href="https://blog.jae.sh/article/w96dk0.html" target="_blank" rel="external">https://blog.jae.sh/article/w96dk0.html</a></p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>网易云音乐最近升级到了v1.1这个版本，但是自从我氪了一波音乐包之后，在Ubuntu下网易云音乐就打不开了，之前以为是江南皮革厂的梗，然后搜了之后才发现很多人有相似的问题，所以在这里介绍一下如何解决这个问题。</p>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ul>
<li>Ubuntu 16.04 LTS + Unity</li>
<li>网易云音乐 v1.1</li>
</ul>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><ul>
<li>无法使用图标启动</li>
<li>在使用命令行<code>netease-cloud-music</code>启动的时候输出错误<code>Local file: &quot;&quot; (&quot;netease-cloud-music&quot;)</code></li>
<li>当使用管理员权限运行的时候就可以正常开启</li>
</ul>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><ol>
<li>将<code>netease-cloud-music</code>二进制文件加入到<code>sudoer</code>组<br> 修改<code>/etc/sudoers</code>文件，追加一句话<code>YOURNAME ALL = NOPASSWD: /usr/bin/netease-cloud-music</code>,替换这句话中的<code>YOURNAME</code>为你登录的用户名，建议使用<code>sudo visudo</code>来编辑<code>/etc/sudoers</code>文件,防止出错。</li>
<li><p>修改网易云音乐桌面快捷方式,加入<code>sudo</code></p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim /usr/share/applications/netease-cloud-music.desktop</div></pre></td></tr></table></figure>
<p> 修改<code>Exec=netease-cloud-music %U</code>这行为<code>Exec=sudo netease-cloud-music %U</code>,加上<code>sudo</code>,这样点击网易云音乐图标就是以管理员权限启动的了，且不用输入密码。</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2018/07/03/拓扑学针对神经网络建模/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/03/拓扑学针对神经网络建模/" itemprop="url">针对神经网络的拓扑学建模</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-03T17:06:45+08:00">
                2018-07-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>渣翻于原文<a href="https://www.ayasdi.com/blog/topology/on-topological-modeling/" target="_blank" rel="external">On Topological Modeling</a></p>
</blockquote>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>对于许多数学建模来说，其都是针对于一些基于在动态模型下微分方程的回归形式。然而其对于一些应用来说显得非常的拘束，举个例子而言，一个聚类算法可以被视为线性回归不适用情况下的拟合机制。分层聚类也被认为是一种数学建模机制，其输出是树形图，包括了不同层级聚类行为的信息。Kohonen自组织（SOM）映射可以视为这种情况的一种简化形式。</p>
<p>拓扑学数据分析也是一类非代数的建模方法。对于这类新的建模方法，我们可以视其为一类对于点云信息集的新的建模方法，这也是我们经常进行数学建模的一种非常自然的延伸。本文将会讨论拓扑建模的方法适用于其他的建模手段。所以，让我们先了解这种建模的一些重要的性质是什么。</p>
<h2 id="压缩性"><a href="#压缩性" class="headerlink" title="压缩性"></a>压缩性</h2><p>所有的建模手段都应该生成一个对于数据集的非常紧凑的表达，对于使用者而言，其应当是非常易懂的。举例而言，线性回归获得一系列数据点，并且用两个数字（w斜率和b偏置）来表达。大多数数据集包含了过多的信息，所以我们需要删除掉一些细节，来获得对于数据集更好的洞察力。</p>
<h2 id="功用性"><a href="#功用性" class="headerlink" title="功用性"></a>功用性</h2><p>拓扑学建模应当允许使用者自定义模型结构的某些特征。举例而言，线性回归允许用户来产生不同的基于模型独立变量的输出。</p>
<h2 id="可解释性"><a href="#可解释性" class="headerlink" title="可解释性"></a>可解释性</h2><p>模型应当能解释其结构。举例而言，聚类模型应当解释聚类的不同的特征在哪。</p>
<h1 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h1><p>我们意识到任意的模型都是针对与数据集的一个代数方程的拟合。其依赖于分析几何，同时几何物体的压缩是经由所有几何对象的可以经过一系列方程组的解表示这个原理所指导。通过这种几何对象的方法来近似数据集也就是整个回归的过程。模型的输出就是一个方程或者方程组。在这种方法下，压缩的性质得以体现，因为由无限多个点组成的几何对象可以由等式中的有限多个系数表示。因为其能具有预测能力，其能具有功用性。同时，其也能提供可解释性。也就是其可以通过研究变量的系数来理解结果变量对于个体自变量的依赖性。虽然这个案例表明代数模型可以适应建模系统的目标，但同样重要的是要注意代数模型通常难以直接用于拟合许许多多的数据。</p>
<p>举例而言，对于下面的对象：</p>
<img src="/2018/07/03/拓扑学针对神经网络建模/example1.png" alt="example1.png" title="">
<p>如果使用代数表达式来表示上述的对象，其通常需要很高维度的方程。因为现在由很多不同的微分系数都能在模型压缩数据之中变化，这也就意味着压缩数据的程度也很低。这说明了，为了包含尽可能多的信息，代数模型通常需要具有较低的阶，比如线性或者二次型。但是可以肯定的是，我们也可以使用除多项式之外的函数族进行回归，但是我们需要很好的找出这个函数族，但是通常来说，我们很难知道哪个函数是合适的。</p>
<h1 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h1><p>聚类分析的结果通常都是对于数据进行分组和分类。在这种情况下，模型的压缩特性可以通过提供聚类来提供，通常来说数据可以被压缩到很小的范围内。这种压缩特性也能够允许人们能够理解这种模型的范式。举例而言，对于糖尿病患者，将其分为1型2型患者。将选民分为保守党、自由党或者中立选民。这种方法在大量数据集中经常出现，通过构造新的数据点针对改点所属的集群进行猜测，并且将该点附加到模型之中。在许多情况下，这种行为也能被很好解释。例如，如果一个数据集包含了多个实例或者条目的向量，则我们可以找到一个单独参数，从而能够很好的区分聚类，或者从整个基于多个数据特征维度来区分聚类。</p>
<h2 id="分层聚类"><a href="#分层聚类" class="headerlink" title="分层聚类"></a>分层聚类</h2><p>分层聚类是一种非常有趣的方法。由于其可以输出一个树状图，它并不是一个代数方程以及划分而是一个非常惊喜的对象。创建此建模方法是为了解决许多聚类算法需要选择阈值的事实，并且通常很难确定正确的阈值（如果有的话）。在这种情况下，我们可以针对数据集进行多次压缩，因为人们通常研究高层结构下的树状图，其含有少量的簇。在这种高维结构的树状图中，因为它可以在每个级别都有对应的集群，同时其也能确定较低级别的给定集群。例如，我们通常使用下面的图片描述动物的分类：</p>
<img src="/2018/07/03/拓扑学针对神经网络建模/animalCluster.png" alt="animalCluster.png" title="">
<p>这显然是对于聚类方法的一个体现，因为其编码了食肉目、鲸类和翼手目都属于高度抽象类下的哺乳动物群。</p>
<h1 id="拓扑学模型"><a href="#拓扑学模型" class="headerlink" title="拓扑学模型"></a>拓扑学模型</h1><p>这是Ayasdi开发的方法。 它产生拓扑网络作为输出，而不是代数方程，分区或树形图。 它提供了大量的压缩后的数据，因为网络的每个节点对应于可能很大的数据点组，并且网络的边缘对应于这些子组的交叉点。 它还提供了大量功能，包括以下可能性：</p>
<ul>
<li>生成的网络布局，用于可视化和无监督分析。</li>
<li>通过使用标准手势方法（例如套索）选择节点组就可以来选择数据集的子组的能力。</li>
<li>给定一组或一系列的组，就可以确定该组与其余数据集的能够“解释变量”。</li>
<li>通过将每个节点着色为对应于节点的集合中的点的数量的平均值，使感兴趣的数量着色网络的能力。</li>
<li>给定外部定义的组，能够通过属于外部定义，给相应组的部分成员的每个节点着色。</li>
<li>创建与网络结构相关的新功能。 这可以包括基于组的“碰撞功能”的类似物，图形距离中的中心度量等。</li>
</ul>
<img src="/2018/07/03/拓扑学针对神经网络建模/topoNetwork.png" alt="topoNetwork.png" title="">
<p>在这个拓扑模型中，可以看到四个不同的白血病亚组（它们是橙色，绿色，黄色和绿蓝色。各种白血病类型都有编号，拓扑模型亚组用每组中白血病类型的平均值着色。 从左到右，橙色组主要包含ALL和B-ALL类型，绿色组几乎是纯CLL，黄色是AML和T-ALL衍生物，蓝绿色组是MDS和CML衍生物。</p>
<p>这些TDL的原始功能可以相互结合使用，以创建以下方法：</p>
<ul>
<li>改进预测模型</li>
<li>根据数据集的网络模型结构提供原则性降维</li>
<li>开发热点分析，以了解数据集中感兴趣的数量或预定义组的分布</li>
</ul>
<p>至于解释性来说，给网络着色可以针对最具区别的变量从而进行类的区分。</p>
<p>这里要做的主要观点是，数学建模不仅限于少量的数学技术应用，而应被视为通过各种信息数学模型来表示数据的科学（和艺术）。 实际上，所有数学学科都包含各种对象，可以作为各种领域的有用模型。 任何方法的关键在于它产生的洞察力，以及它在多大程度上支持和加速数据科学家试图从数据中提取知识的工作。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2018/05/22/迁移学习初步/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/22/迁移学习初步/" itemprop="url">迁移学习初步</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-22T12:44:26+08:00">
                2018-05-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="什么是迁移学习"><a href="#什么是迁移学习" class="headerlink" title="什么是迁移学习"></a>什么是迁移学习</h1><p>迁移学习的研究来源于一个观测：人类可以将以前学到的知识应用于解决新的问题，从而提高解决问题的效率或取得更好的效果。因此迁移学习被赋予这样一个任务：从以前的任务当中去学习知识（knowledge）或经验，并应用于新的任务当中。换句话说，迁移学习的目的是从一个或多个源任务（source tasks）中抽取知识、经验，然后应用于一个有相关性的目标领域（target domain）中去。[1] 顾名思义就是就是把已学训练好的模型参数迁移到新的模型来帮助新模型训练。考虑到大部分数据或任务是存在相关性的，所以通过迁移学习我们可以将已经学到的模型参数（也可理解为模型学到的知识）通过某种方式来分享给新模型从而加快并优化模型的学习效率不用像大多数网络那样从零学习（starting from scratch，tabula rasa）。这里迁移学习通过Source / Target Domain Label就可以更为细节的分支为下面的几个方向</p>
<table>
<thead>
<tr>
<th>Transfer Learning Setting（迁移学习设定）</th>
<th>相关领域</th>
<th>源空间标签是否存在</th>
<th>目标空间标签是否存在</th>
<th>任务</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inductive transfer learning(归纳迁移学习)</td>
<td>多任务学习</td>
<td>存在</td>
<td>存在</td>
<td>回归或者分类</td>
</tr>
<tr>
<td>Inductive transfer learning(归纳迁移学习)</td>
<td>自我启发式学习</td>
<td>不存在</td>
<td>存在</td>
<td>回归或者分类</td>
</tr>
<tr>
<td>Transductive transfer learning(归纳迁移学习)</td>
<td>空间自适应，采样偏差，边缘分布变换</td>
<td>存在</td>
<td>不存在</td>
<td>回归或者分类</td>
</tr>
<tr>
<td>Unsupervised transfer learning(无监督迁移学习)</td>
<td></td>
<td>不存在</td>
<td>不存在</td>
<td>聚类或者降维</td>
</tr>
</tbody>
</table>
<h2 id="数学定义"><a href="#数学定义" class="headerlink" title="数学定义"></a>数学定义</h2><p>假定现在有一个源空间 $ D_S = {X_S,f_S(X)} $和一个学习任务$ T_s $，一个目标空间$ D_T = {X_T,f_T(X)} $以及一个学习任务 $ T_T $， 迁移学习目的是帮助依据$ D_S $和$ T_S $的知识，在$ D_T $域内的求得目标预测函数$ f_T(X) $，其中$ D_S\neq D_T$或者$ T_S\neq T_T$ .</p>
<p>在 inductive 的迁移学习里，我们有 Target Domain 的 Ground Truth Label，这就意味着我们想要迁移的数据所在 Domain 将直接会学习网络和其特征提供指导作用（假设用深度学习方法，则通过Back-progagation方式）。</p>
<p>理论上，任何领域之间都可以做迁移学习。但是，如果源域和目标域之间相似度不够，迁移结果并不会理想，出现所谓的负迁移情况。比如，一个人会骑自行车，就可以类比学电动车；但是如果类比着学开汽车，那就有点天方夜谭了。如何找到相似度尽可能高的源域和目标域，是整个迁移过程最重要的前提。</p>
<h1 id="领域自适应问题"><a href="#领域自适应问题" class="headerlink" title="领域自适应问题"></a>领域自适应问题</h1><p>也就是Domain Adaptation，同构迁移学习，其具有下面的基本假设：</p>
<ul>
<li>数据分布的角度：源域和目标域的概率分布相似（最小化概率分布距离）</li>
<li>特征选择的角度：源域和目标域共享某些特征（选择出公共特征）</li>
<li>特征变化的角度：源域和目标域共享某些子空间（把两个域变换到相同的子空间）</li>
</ul>
<img src="/2018/05/22/迁移学习初步/distribution_adaptation.png" alt="概率分布适配法" title="概率分布适配法">
<img src="/2018/05/22/迁移学习初步/feature_selection.png" alt="特征选择法" title="特征选择法">
<img src="/2018/05/22/迁移学习初步/subspace_learning.png" alt="子空间学习法" title="子空间学习法">
<h2 id="概率分布适配"><a href="#概率分布适配" class="headerlink" title="概率分布适配"></a>概率分布适配</h2><ul>
<li>边缘分布适配（Marginal distribution adaptation）<ul>
<li>假设: $ P(X_S) \neq P(X_t) $</li>
</ul>
</li>
<li>条件分布适配（Conditional distribution adaptation）<ul>
<li>假设: $ P(y_S | X_S) \neq P(y_t | X_t) $</li>
</ul>
</li>
<li>联合分布适配（Joint distribution adaptation）<ul>
<li>假设: $ P(X_S,y_S) \neq P(X_t,y_t) $</li>
</ul>
</li>
</ul>
<img src="/2018/05/22/迁移学习初步/distribution_adaption_trans.png" alt="概率分布适配法" title="概率分布适配法">
<h3 id="边缘分布适配"><a href="#边缘分布适配" class="headerlink" title="边缘分布适配"></a>边缘分布适配</h3><ul>
<li>迁移成分分析（Transfer Component Analysis），其优化目标为$$ min Dist(\varphi (X_S),\varphi(X_T)) + \lambda \Omega(\lambda) $$</li>
</ul>
<p>$$ s.t. constraints~on~\varphi(X_S) and \varphi(X_T) $$</p>
<ul>
<li>最大均值差异（Maximum Mean Discrepancy） $$ Dist(P(X_S),P(X_T)) = ||\frac{1}{n_S} \sum_{i=1}^{n_S} \Phi (x_{S_{i}}) - \frac{1}{n_T} \sum_{j=1}^{n_T} \Phi(x_{S_{j}})||_{H} $$  </li>
</ul>
<img src="/2018/05/22/迁移学习初步/transfer_component_analysis.png" alt="迁移成分分析" title="迁移成分分析">
<ul>
<li>迁移成分分析（TCA）的扩展<ul>
<li>Adaptating Component Analysis（ACA）$ max~\dfrac{tr(HK_{X}HL_{\Phi})}{tr(HK_{M}HL_{\Phi})} $ 也就是最小化MMD，同时维持迁移过程之中目标域的结构</li>
<li>Domain Transfer Multiple Kernel Learning 多核MMD</li>
<li>Deep Domain Confusion 把MMD加入到神经网络中</li>
<li>Deep Adaptation Network（DAN）把MKK-MMD加入到神经网络之中</li>
<li>Distribution-Matching Embledding（DME）先计算变换矩阵，在进行映射</li>
<li>Central Moment Discrepancy（CMD）k阶MMD</li>
</ul>
</li>
</ul>
<h3 id="条件分布适配"><a href="#条件分布适配" class="headerlink" title="条件分布适配"></a>条件分布适配</h3><blockquote>
<p>Domain Adaptation of Conditional Probability Models via Feature Subsetting</p>
</blockquote>
<p>主要就是条件随机场和分布适配，其优化目标为: $$argmax_{w,s}~ \sum_{(x,y)\in D}\sum_{k\in S} \omega_k f_k(x,y) - \log z_w(x) $$<br>$$ such~that~dist(D,D’|S,D’) \leq \epsilon$$</p>
<blockquote>
<p>Conditional Transferrable Components (CTC)</p>
</blockquote>
<p>定义条件转移成分,对其进行建模</p>
<img src="/2018/05/22/迁移学习初步/CTC.png" alt="条件分布适配" title="条件分布适配">
<h3 id="联合分布适配"><a href="#联合分布适配" class="headerlink" title="联合分布适配"></a>联合分布适配</h3><p>直接继承于TCA，但是加入了条件分布适配，其优化目标为$ D(D_s,D_t) \approx D(P(x_s),P(x_t)) + D(P(y_s|x_s),P(y_t|x_t)) $</p>
<p>这样我们可以使用一个充分统计量，也就是类条件概率近似条件概率，也就是用一个弱分类器生成目标域的初始软标签，所以最终的优化形式为$ \min_{A^TKHK^TA = I} \sum_{c=0}^{C} tr(A^TKM_cK^TA) + \lambda||A||^2_{F} $</p>
<p>联合分布适配的结果普遍优于单独适配边缘或者条件分布</p>
<p>联合分布适配方法的一些扩展：</p>
<ul>
<li>Adaptation Regularization（ARTL）分类器学习+联合分布适配</li>
<li>Visual Domain Adaptation（VDA）加入类间距、类内距</li>
<li>Joint Geometrical and Statistical Alignment（JGSA）加入类间距、类内距和标签适配</li>
<li>或者加入结构不变性控制</li>
<li>目标域选择</li>
<li>Joint Adaptation Network（JAN）提出JMMD度量，在深度网络中进行联合分布适配</li>
</ul>
<p>在这里，还有一类非常重要的，联合分布适配（Balanced Distribution Adaptation, BDA），这里使用<strong>平衡因子</strong>来动态衡量两种分布的重要性，也就是$ D(D_s,D_t) \approx (1-\mu)D(P(x_s),P(x_t)) + \mu D(P(y_s|x_s),P(y_t|x_t)) ~ \mu \in [0,1] $</p>
<ul>
<li>当$ \mu \rightarrow 0 $，表示边缘分布更占优，应该优先适配</li>
<li>当$ \mu \rightarrow 1 $，表示条件分布更占优，应该优先适配</li>
</ul>
<p>最终表达形式为：$$ min~ tr(A^TX((1-\mu)M_0+\mu \sum_{c=1}^{C}M_c)X^TA) + \lambda ||A||^2_F $$<br>$$ s.t.~ A^TXHX^TA = I, ~0\leq \mu \leq 1 $$</p>
<p>平衡银子的重要性在于：对于不同的任务，边缘分布和条件分布并不是同等重要，因此，BDA方法可以有效衡量这两个分布的权重，从而达到最好的结果。</p>
<img src="/2018/05/22/迁移学习初步/BDA.png" alt="联合分布适配" title="联合分布适配">
<p>平衡银子的求解和估计来说，目前没有精确估计方法，我们一般使用<strong>A距离</strong>来进行估计</p>
<ul>
<li>求解源域和目标域整体的A距离</li>
<li>对目标域聚类，计算源域和目标域每个类的A距离</li>
<li>计算上述两个距离的比值，也就是平衡因子</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>大部分方法都是基于MMD距离进行优化求解，然后可以分别进行边缘/条件/联合概率适配，在效果上，平衡 (BDA) &gt; 联合 (JDA) &gt; 边缘 (TCA) &gt; 条件。</p>
<ul>
<li>数据整体差异性大 (相似度较低),边缘分布更重要</li>
<li>数据整体差异性小 (协方差漂移),条件分布更重要</li>
</ul>
<p>使用深度学习和分布适配往往有更好的效果。</p>
<img src="/2018/05/22/迁移学习初步/BDA_summary.png" alt="BDA、JDC和TCA精度比较" title="BDA、JDC和TCA精度比较">
<img src="/2018/05/22/迁移学习初步/BDA_summary2.png" alt="BDA、JDC和TCA精度比较" title="BDA、JDC和TCA精度比较">
<h2 id="特征选择法"><a href="#特征选择法" class="headerlink" title="特征选择法"></a>特征选择法</h2><p>从源域和目标域中选择提取共享的特征,建立统一模型，寻找Pivot feature,将源域和目标域进行对齐。<br><img src="/2018/05/22/迁移学习初步/feature_selection.png" alt="特征选择法" title="特征选择法"></p>
<p>扩展有：</p>
<ul>
<li>Joint feature selection and subspace learning 特征选择/变换+子空间学习<ul>
<li>优化目标:$$ min_A ||A||_{2,1} + \mu tr(A^TXLX^TA), s.t. A^TXDX^TA = I $$</li>
</ul>
</li>
<li>Transfer Joint Matching (TJM) MMD分布适配+源域样本选择<ul>
<li>优化目标: $$ \min_{A^TKHK^TA = I} tr(A^TKHK^TA)+\mu (||A_s||_{2,1}+||A_t||_F^2) $$</li>
</ul>
</li>
<li>Feature Selection and Structure Preservation (FSSL) 特征选择+信息不变性<ul>
<li>优化目标:$$ \min_{P,Z,E} ||P||_{2,1} + \frac{\mu}{2} tr(P^TXLX^TP) + \frac{\beta}{2} ||Z||^2_F + \gamma ||E||_1 ,~~ s.t. P^TX_sZ+E,  P^TXDX^TP = I$$</li>
</ul>
</li>
</ul>
<p>其特点有：</p>
<ul>
<li>从源域和目标域中选择提取共享的特征,建立统一模型</li>
<li>通常与分布适配进行结合</li>
<li>选择特征通常利用稀疏矩阵</li>
</ul>
<h2 id="子空间学习法"><a href="#子空间学习法" class="headerlink" title="子空间学习法"></a>子空间学习法</h2><p>将源域和目标域变换到相同的子空间,然后建立统一的模型</p>
<ul>
<li>统计特征变换 (Statistical Feature Transformation)<ul>
<li>将源域和目标域的一些统计特征进行变换对齐</li>
</ul>
</li>
<li>流形学习 (Manifold Learning)<ul>
<li>在流形空间中进行子空间变换</li>
</ul>
</li>
</ul>
<img src="/2018/05/22/迁移学习初步/Subspace1.png" alt="子空间学习法" title="子空间学习法">
<img src="/2018/05/22/迁移学习初步/Subspace2.png" alt="子空间学习法" title="子空间学习法">
<h2 id="统计特征变换"><a href="#统计特征变换" class="headerlink" title="统计特征变换"></a>统计特征变换</h2><h3 id="子空间对齐法-Subspace-Alignment-SA"><a href="#子空间对齐法-Subspace-Alignment-SA" class="headerlink" title="子空间对齐法 (Subspace Alignment, SA)"></a>子空间对齐法 (Subspace Alignment, SA)</h3><ul>
<li>直接寻求一个线性变换,把source变换到target空间中</li>
<li>优化目标: $$ F(M) = ||X_SM-X_T||^2_F $$ $$ M^* = argmin_M(F(M)) $$</li>
<li>直接获得线性变换的闭式解: $$ F(M) = ||X_S’X_SM-X_S’X_T||^2_F = ||M-X_S’X_T||^2_F $$</li>
</ul>
<p>子空间对齐+概率分布适配 $$ M_s = S_sT_TA_TS_t^T = S(S^TS)(E_s^{-\frac{1}{2}}E_t^{\frac{1}{2}})S^T $$</p>
<h3 id="关联对齐法-CORrelation-Alignment-CORAL"><a href="#关联对齐法-CORrelation-Alignment-CORAL" class="headerlink" title="关联对齐法 (CORrelation Alignment, CORAL)"></a>关联对齐法 (CORrelation Alignment, CORAL)</h3><ul>
<li>最小化源域和目标域的二阶统计特征，其优化目标为：$ \min_{A} = ||C_S - C_T||^2_F = \min_{A}||A^TC_sA-C_T||^2_F $</li>
<li>形式简单，求解高效</li>
</ul>
<h3 id="深度关联对齐-Deep-CORAL"><a href="#深度关联对齐-Deep-CORAL" class="headerlink" title="深度关联对齐 (Deep-CORAL)"></a>深度关联对齐 (Deep-CORAL)</h3><p>深度学习之中加入CORAL，$ CORAL = \frac{1}{4d^2}||C_S-C_T||^2_F $</p>
<h3 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h3><h4 id="采样测地线留方法（Sample-Geodesic-Flow）"><a href="#采样测地线留方法（Sample-Geodesic-Flow）" class="headerlink" title="采样测地线留方法（Sample Geodesic Flow）"></a>采样测地线留方法（Sample Geodesic Flow）</h4><ul>
<li>把领域自适应的问题看成一个增量式“行走”问题</li>
<li>从源域走到目标域就完成了一个自适应过程</li>
<li>在流形空间中采样有限个点,构建一个测地线流</li>
</ul>
<h4 id="测地线流式核方法-Geodesic-Flow-Kernel-GFK"><a href="#测地线流式核方法-Geodesic-Flow-Kernel-GFK" class="headerlink" title="测地线流式核方法 (Geodesic Flow Kernel, GFK)"></a>测地线流式核方法 (Geodesic Flow Kernel, GFK)</h4><ul>
<li>继承了SGF方法,采样无穷个点</li>
<li>转化成Grassmann流形中的核学习,构建了GFK</li>
<li>优化目标:$ (z_i^\infty,z_j^\infty) = \int_0^1 (\Phi(t)^Tx_i)^T (\Phi(t)^Tx_j)^T dt = x_i^TGx_j $</li>
</ul>
<img src="/2018/05/22/迁移学习初步/SGF.png" alt="SGF法" title="SGF法">
<img src="/2018/05/22/迁移学习初步/GFK.png" alt="GFK法" title="GFK法">
<h4 id="域不变映射-Domain-Invariant-Projection-DIP-Baktashmotlagh-CVPR-13"><a href="#域不变映射-Domain-Invariant-Projection-DIP-Baktashmotlagh-CVPR-13" class="headerlink" title="域不变映射 (Domain-Invariant Projection, DIP) [Baktashmotlagh,CVPR-13]"></a>域不变映射 (Domain-Invariant Projection, DIP) [Baktashmotlagh,CVPR-13]</h4><ul>
<li>直接度量分布距离是不好的:原始空间特征扭曲</li>
<li>仅作流形子空间学习:无法刻画分布距离</li>
<li>解决方案:流形映射+分布度量</li>
</ul>
<h4 id="统计流形法-Statistical-Manifold-Baktashmotlagh-CVPR-14"><a href="#统计流形法-Statistical-Manifold-Baktashmotlagh-CVPR-14" class="headerlink" title="统计流形法 (Statistical Manifold) [Baktashmotlagh, CVPR-14]"></a>统计流形法 (Statistical Manifold) [Baktashmotlagh, CVPR-14]</h4><ul>
<li>在统计流形(黎曼流形)上进行分布度量</li>
<li>用Fisher-Rao distance (Hellinger distance)进行度量</li>
</ul>
<p>$$ \min_\alpha = \dfrac{1}{\sum_{i=1}^{n_s}\alpha_i} \sum_{i=1}^{n_s} \alpha_i (\sqrt{T(x_i^s)}- \sqrt{1-T(x_i^s)} )^2 + \dfrac{1}{n_t} \sum_{i=1}^{n_s} (\sqrt{T(x_i^s)}- \sqrt{1-T(x_i^s)})^2 $$</p>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><ul>
<li>主要包括统计特征对齐和流形学习方法两大类</li>
<li>和分布适配结合效果更好</li>
<li>趋势:与神经网络结合</li>
</ul>
<h1 id="最新成果"><a href="#最新成果" class="headerlink" title="最新成果"></a>最新成果</h1><ul>
<li>与深度学习结合<ul>
<li>Deep Adaptation Networks (DAN) [Long, ICML-15] 深度网络+MMD距离最小化</li>
<li>Joint Adaptation Networks (JAN) [Long, ICML-17] 深度网络+联合分布距离最小化</li>
<li>Simultaneous feature and task transfer [Tzeng, ICCV-15] 特征和任务同时进行迁移</li>
<li>Deep Hashing Network (DHN) [CVPR-17] 在深度网络中同时学习域适应和深度Hash特征</li>
<li>Label Efficient Learning of Transferable Representations across Domains and Tasks [Luo, NIPS-17] 在深度网络中进行任务迁移</li>
</ul>
</li>
<li>与对抗学习进行结合<ul>
<li>Domain-adversarial neural network 深度网络中加入对抗 [Ganin, JMLR-16]</li>
<li>Adversarial Discriminative Domain Adaptation (ADDA) [Tzeng, arXiv-17] 对抗+判别</li>
</ul>
</li>
<li>开放世界领域自适应 <ul>
<li>Open set domain adaptation [Busto, ICCV-17] 当源域和目标域只共享一部分类别时如何迁移?</li>
</ul>
</li>
<li>与张量 (Tensor)表示相结合<ul>
<li>When DA Meets tensor representation [Lu, ICCV-17] 用tensor的思想来做领域自适应</li>
</ul>
</li>
<li>与增量学习结合 Learning to Transfer (L2T) [Wei, arXiv-17] 提取已有的迁移学习经验,应用于新任务</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://www.zhihu.com/question/41979241" target="_blank" rel="external">什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？ - 知乎</a></li>
<li><a href="http://jd92.wang/assets/files/l12_da.pdf" target="_blank" rel="external">迁移学习 Transfer Learning</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2018/01/12/Scienece年度概率图神文/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/12/Scienece年度概率图神文/" itemprop="url">Scienece年度概率图神文</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-12T17:18:52+08:00">
                2018-01-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>辣鸡翻译了解一下</strong></p>
<blockquote>
<p>年度神文标题：<a href="http://science.sciencemag.org/content/358/6368/eaag2612" target="_blank" rel="external">A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs</a></p>
<p>项目主页见 <a href="https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/" target="_blank" rel="external">https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/</a></p>
<p>源代码可以看见 <a href="https://github.com/vicariousinc/science_rcn" target="_blank" rel="external">https://github.com/vicariousinc/science_rcn</a></p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>其主要是用于处理验证码的问题，因为其加入了隔断和一些非常拥挤的文字，这样就使得整个算法让分割器和鉴别器变成了一个典型的鸡和蛋的问题：分割字符需要分割器来帮助，而分割器需要能对于字符有着很好的理解的能力，然而这些字符可能以其他的方式被组合成其他的数字。最新的解决验证码的深度学习的方法依赖于庞大的已经标记的数据作为驱动，早期的方法大的部分依赖于人工的校正和分割，而人并不需要任何刻意的训练就能解决新形式下的验证码。其实这种理解方式也正如同图1所示那样。（图A说明了人非常善于解析那些不熟悉的验证码，B说明了同一个字符刻意被渲染成不同形式的样子，可是人们还是能够在这些图片中检测到A这个字符C说明了尝试和直接都能很容的影响人们对于字符的感知，就比如说图i的m u以及n，在图中是很难分得清的。ii说的是遮挡物的位置，三条很简单的线能够被解释成N和S，iii说的是感知可以帮助人理解bison和bike这两个单词。）</p>
<img src="/2018/01/12/Scienece年度概率图神文/Fig1.png" alt="人类对于字符变化感知的灵活性" title="人类对于字符变化感知的灵活性">
<p>在这里其引入了一种带有等级制度的网络，其被称为迭代皮质网络（Recursive Cortical Network (RCN)），其从神经科学的角度解释了一个具有结构的基于概率生成的模型。其在之后把这个模型还应用到其他的训练的例子之中，诸如解析验证码、遮挡推理和基于情景的文字识别。</p>
<h1 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h1><p>这篇文章从神经科学系统之中获得灵感，其引进了一个基于概率的生成模型来处理视觉问题。其原理在于基于信息传递的推理、分割以及推理。这个模型在泛化性能和物体遮挡推理的能力上有着极大的能力。（CapsNet也善于物体遮挡的推理）RCN是基于现有的一个复合模型之中建立。</p>
<h2 id="现有的基于规则模型的缺陷"><a href="#现有的基于规则模型的缺陷" class="headerlink" title="现有的基于规则模型的缺陷"></a>现有的基于规则模型的缺陷</h2><p>基于规则的模型总伴随着下面的缺陷：</p>
<ul>
<li>限制了单棵树的辨析能力</li>
<li>使用属性关系的时候使得计算变得不可解</li>
</ul>
<p>基于树状的复合模型能够简化推断但是又由于缺乏横向的约束使之缺失了选择能力。</p>
<img src="/2018/01/12/Scienece年度概率图神文/captcha_as.png" alt="captcha_as.png" title="">
<p>RCN建立于复合模型之中的许许多多的灵感，诸如</p>
<ul>
<li>等级结构</li>
<li>逐步建立的不变性</li>
<li>为了选择性使用横向连接</li>
<li>轮廓表面分解</li>
<li>基于联合解释的解析</li>
</ul>
<p>将其结合到有序的概率图形模型之中。信念传播算法就能作为一个基础的推断引擎了（类似于反向传播算法在神经网络之中的运用）。</p>
<h1 id="RCN的表达能力"><a href="#RCN的表达能力" class="headerlink" title="RCN的表达能力"></a>RCN的表达能力</h1><p>在RCN之中，我们解析的对象是按照轮廓和表面的组合所建立的模型。轮廓出现在面的边界，同时物体的外壳，物体和物体之间的表面之间的边界从而组成了一个对象的轮廓。而表面则是使用条件随机场（CRF）建模，其能捕捉表面特征变化的平滑性。轮廓由复合的不同等级的特征所组成。分权重的轮廓（形状）和表面（外表）使得模型能够识别不同的物体而不需要精疲力竭的训练了。</p>
<img src="/2018/01/12/Scienece年度概率图神文/Fig2.png" alt="RCN的结构" title="RCN的结构">
<blockquote>
<p>图2 RCN的结构 （A）一个等级产生一个对象的轮廓，条件随机场产生对象的表面。（B）在轮廓层次结构的同一层次上的两个子网络通过制作子特征的父特定副本并将它们与父特定侧相连接来保持单独的横向连接，被绿色举行所包含的节点就是被标记为e特征的拷贝。（C）一个三级的RCN代表着一个正方体的轮廓，处于第二层的特征代表着四个角，每个角代表着四条由线段分割的特征（D）四层网络代表字符<code>A</code></p>
</blockquote>
<p>图2B显示了一个带轮廓等级的RCN层的两个子网络（黑和蓝）。图中的实心和空心圆点是一个二进制的随机变量，其分别对应着特征和池化。没一个特征节点都会与子节点编码一个和的关系，每一个池化变量都会和子节点编码一个或的关系，比较近似于<code>和-或图</code>。长方形的因子节点其代表着侧向的约束，其能够协调其选择连接的池化。这两个子网络能够对应着两个物体或者物体的部件，其共享底层维度上的特征。</p>
<p>图2C显示了一个三层的网络来表示一个正方形的轮廓，处于最低级、中间和顶层的特征分别代表着线段、拐角和整个正方形。每个池化的变量都汇集相对于中心特征以不同的变形，小的转义、大小的变化，这样就能引入相应的对应不变形的这个特征。没有两个池化之间的侧向连接，由一个表示拐角特征节点就会产生未对齐的线段，正如图3A所示那样。在两个池化之间的侧向链接通过保证一个池中的特征能影响其链接的池的特征，从而能能够提供选择性，这样就能产生那些轮廓变化更平滑的样本。侧向连接的限制的灵活性由干扰因素所控制，其也是在每层所指定的一个超参数。通过多层特征的汇集，侧向连接以及组合，处于顶层的特征节点就能够识别一个具有一定程度的尺度、形变变化的物体了。</p>
<p>多个物体都以同样的等级结构所表达，这些结构之间具有共享的部分。当多个亲本收集一个单独的子特征的时候，这个子特征就会被激活从而使得每个亲本也都会被激活（在图中的或门），并且不同于在和或门之中的独享结构，在一定条件下，子特征能够成为亲本特征的一部分。甚至当两个最高层的特征分享了一些相同的底层特征和池，高级的特征的侧连接仍然通过对其相关的每个底层特征进行复制从而保持独立。类似于高阶网络中使用的状态复制机制，横向网络的亲本特定拷贝用于实现与成对连接的高阶交互。这对于消息传递来说很重要，以实现准确的结果，并且其让人联想到双重分解中使用的技术。等级制度在RCN网络有两个作用。首先，其能允许变形的表达逐渐的在每层中表现，从而使跨层的变量发生变化。其次，等级制度也使得在两个不同的对象之间通过共享特征来加速效率。</p>
<img src="/2018/01/12/Scienece年度概率图神文/Fig3.png" alt="图3" title="图3">
<p>图3 A. 比较存在或去除侧连接下的拐角特征的样本 B. 来自不同变形情况下字符A的例子，其被汇集池和侧连接的超参数所决定。这个三层的等级就比较类似于图2D，最低层的特征几乎都是边，第二行则是显示了在层之间的变形性的分布，这样就会产生局部变形和全局演变。其他列则是显示了一些非常极限的情况。 C. 显示了一个立体的表面的条件随机场的轮廓，绿色的节点表示了由前景到北京的边，而蓝色的则是直接显示了对象的边。D. 在立体形状下的C的不同表面</p>
<h1 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h1><p>为了解析场景，RCN在多个位置对于多个对象实体维护了一个等级的图。场景的解析可以通过最大后验概率（Maximum A Posterior）的方法来推断，这个图能够以实体对象和分割来恢复一个最佳的连接配置。这个RCN网络是受皮质的推断所启发而来。首先输入的图像会接受<code>PreProc</code>的方法，其将使用类<a href="https://en.wikipedia.org/wiki/Gabor_filter" target="_blank" rel="external">Gabor</a>的滤波把像素值转换为对于边的可能性。接着，在网络之中传输的正向和反向的信息就会对这个对象进行假设的局部匹配，并且通过对于在假设对象的图进行场景解析，解决一个完全的近似MAP的问题。正向的传递将会给予顶层节点的概率以一个上确界，而反向的传输则会遍历正向传播假设之中的高概率路径，这个行为比较类似于一个自顶而下的注意力机制（Attention机制）的过程。这个条件的推断会假设所有其他的节点都处于关闭（类似于Dropout）的状态以便找到这个物体的近似MAP配置。（如图4）反向传播能够拒绝很多在正向传播中被错误标记正确的假设。</p>
<img src="/2018/01/12/Scienece年度概率图神文/Fig4.png" alt="图4" title="图4">
<blockquote>
<h2 id="Gabor滤波器"><a href="#Gabor滤波器" class="headerlink" title="Gabor滤波器"></a>Gabor滤波器</h2><p>使用一个三角函数(如正弦函数)与一个高斯函数叠加我们就得到了一个Gabor滤波器，其是一个用于纹理分析的线性滤波。基本上其分析在点或区域周围的区域的特定方向上是否存在特定频率内容，其善于分析纹理的表示和辨别</p>
</blockquote>
<p>全局的MAP配置就是通过正向和反向传播所产生的所有对象假设的一个子集。在场景之中对象的数量能够被推断为MAP解的一个部分。同时，搜索这么大的一个子集，需要在高阶的情况下推导，于是作者就开发了一个动态规划算法，从而能在线性时间内解决这个问题，这个动态规划算法利用了每个对象的假设都会占有了一个能被用2D掩码所表示的连续区域。当考虑到结合对象的假设，我们就能产生一个连续的空间并且他们的2D掩码也重叠，从而我们利用掩码包含关系来对他们进行一个拓扑排序。在这种情况下，我们就能在一个O（n）的数量级的情况下迭代地解决这个问题。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2018/01/04/Capsules架构小结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/04/Capsules架构小结/" itemprop="url">Capsules架构小结</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-04T15:26:21+08:00">
                2018-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="何谓CapsNet"><a href="#何谓CapsNet" class="headerlink" title="何谓CapsNet"></a>何谓CapsNet</h1><p>在去年，Hinton提出了一个新的“胶囊”的概念来处理图像识别的问题，经过论文的证实，其取得了比CNN更好的效果。在这里，我简要的介绍一下关于CapsNet的内容。</p>
<blockquote>
<p>论文来源：<a href="https://arxiv.org/abs/1710.09829" target="_blank" rel="external">https://arxiv.org/abs/1710.09829</a></p>
</blockquote>
<h1 id="为何提出了这个框架"><a href="#为何提出了这个框架" class="headerlink" title="为何提出了这个框架"></a>为何提出了这个框架</h1><p>在人类对于图像的识别中，往往我们会从图像中知道很多性质的实体。举例而言，位置、大小、方向、变形程度、速度、物件表面的反射率、气氛和纹理等都是我们识别图片的重要依赖。一个非常重要的特点就是在图像之中的实体，一个能显著表示其存在的方法就是使用一个逻辑单元，其输出的是这个实体是否存在的概率。在这个文章里面他们使用含有实体参数向量的总长度来表示实体的存在的概率（其不能大于100%，也就是1），而用其方向来表示实体的属性。</p>
<h1 id="routing-by-agreement策略"><a href="#routing-by-agreement策略" class="headerlink" title="routing by agreement策略"></a>routing by agreement策略</h1><p>这篇文章主要提出了一个强大的动态路由的规则使得“胶囊”在该层输出一个合适的亲本。</p>
<p>在起始阶段，CapsNet会输出所有可能的亲本，但是输出会被亲本的系数所重置，其系数的和为1。对于没一个可能的亲本，<code>Capsule</code>将会通过把它的输出和一个权重矩阵相乘计算出一个预测的矢量。如果这个预测的矢量比某一个可能的亲本的输出还要大的话，一个从上到下的反馈就会启动。这个反馈将会增大对应亲本的系数并且减小其他亲本的输出。这个策略将会比原始形式的<code>max-pooling</code>（最大池化）更有效率，池化使得在一个层里的神经元只会关注到最活跃的特征而舍弃其他的特征。在针对高度重叠的物件的分割之中，这种新的策略能够非常有效地执行“解释（原文是explaining away）”的作用。</p>
<p>卷积神经网络使用已经学习过特征的解释的副本来工作，其允许他们在图片中某个位置利用合适的权值来工作，这也在图像识别中被证实非常有用。尽管我们用使用routing-by-agreement的矢量输出<code>胶囊</code>和最大池化的方法来取代标量输出的CNN，我们仍然希望知道数据在空间的分布。所以我们将会把除了最后一层的胶囊层都使用卷积的方法。在CNN的协助下，我们将会使用高层的胶囊来处理更大面积上的图像。与最大池化的方法不一样，我们并不会丢失任何关于实体处于区域之中的精确位置信息。对于低维的胶囊来说，未知的信息将会被活跃的胶囊所编码。当我们升序按照等级排序的时候，越来越多的位置信息将会被胶囊输出的矢量的实值所“rate-coded”（率编码）。这种由对位置编码到率编码的转变伴随着高层的胶囊在更大自由度上能表达更复杂的实体信息。也就是说，胶囊的维度随着我们增加等级的同时，其也随之上升。</p>
<h1 id="矢量的胶囊输入和输出是如何被计算的"><a href="#矢量的胶囊输入和输出是如何被计算的" class="headerlink" title="矢量的胶囊输入和输出是如何被计算的"></a>矢量的胶囊输入和输出是如何被计算的</h1><p>其主要的是，胶囊的输出矢量长度代表着实体的可能性。我们因此就是用一个非线性的“压扁”函数来确保短的矢量长度压到接近于0而长矢量的长度压缩到接近于1。</p>
<p>$$ v_j = \frac{||s_j||^2}{1+||s_j||^{2}} \frac{s_j}{||s_j||} $$</p>
<p>$ v_{j} $ 就是第 $ j $ 个胶囊的矢量输出，$ s_{j} $ 是总体的输入</p>
<p>对于除了第一个层的胶囊来说，一个$ s_{j} $的胶囊的总体的输入是一个对于预测矢量的加权和，也就是</p>
<p>$$ s_{j} = \sum_{i} c_{ij} \hat{u}_{j|i} $$</p>
<p>$$ \hat{u}_{j|i} = W_{ij}u_{i} $$</p>
<p>$ c_{ij} $是动态路由过程之中的参数。</p>
<p>在胶囊$ i $ 和所有胶囊层的系数相加的和为1并且其也会被“routing softmax”所决定的。而其初始值$ b_{ij} $就是对数的先验概率，$ i $和$ j $的胶囊的匹配的系数应该就是</p>
<p>$$ c_{ij} = \frac{exp(b_{ij})}{\sum_{k}exp(b_{ik})} $$</p>
<p>这个对数的先验概率可以因为对称性取得其他的权重。他们仅仅取决于位置和胶囊的类型，其不依赖于现有的输入的图像。初始的系数对接下来就被通过衡量现有的输出$ v_j $ 和是由j层第i个胶囊给出的预测值 $ \hat{u}_{j|i} $来迭代刷新值.</p>
<p>相似度的值可以通过 $ a_{ij} = v_{j} \hat{u}_{j|i} $ 。当其是一个对数的相似值并且被加到初始的逻辑单元的时候，这个相似值就会被处理。在在计算将胶囊$ i $连接到更高级别胶囊的所有相关系数的新值之前。</p>
<p>在卷积的胶囊层里面，没一个胶囊都会输出一个胶囊在本地网格的矢量。对于每个网格和胶囊，其都会使用不同的变换的方式。</p>
<p>下面就是路由的算法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">procedure ROUTING(u j|i,r,l)</div><div class="line">  对于所有的在l层的胶囊i并且在l+1层的胶囊j，令bij = 0</div><div class="line">  迭代r次：</div><div class="line">    对于在l层的所有胶囊i有:ci=softmax(bi)</div><div class="line">    对于在l+1层的胶囊j有:sj = sum cij uj|i</div><div class="line">    对于在l+1层的胶囊j有:vj = 压扁(sj)</div><div class="line">    对于在l层的胶囊i和l+1层的胶囊j有:bij = bij + uj|i * vj</div></pre></td></tr></table></figure>
<h1 id="边缘分布"><a href="#边缘分布" class="headerlink" title="边缘分布"></a>边缘分布</h1><p>Capsule使用一个矢量来表达胶囊实体存在的可能性。对于最顶层的胶囊来说，当且仅当这一位在图片中出现的时候，对应的第k类将会有一个长的实例化向量。为了其能够适用于不同的类，对于每一个类所对应的胶囊，我们将会使用一个单独的边缘分布$L_{k}$：</p>
<p>$$ L_{k} = T_{k} \max(0,m^{+}-||v_{k}||)^{2} + \lambda (1-T_{k}) \max(0,||v_{k}||-m^{-})^2 $$</p>
<p>若存在k类的数字，则$ T_{k} = 1 $，与此同时$ m^{+} = 0.9 $ ，$ m^{-} = 0.1 $。损失的$ \lambda $降权重将会针对其他无关的类，最初从缩短所有胶囊的矢量的长度中学习的情况也会被终止。这里我们使用$ \lambda = 0.5 $。总的损失就仅仅是其他胶囊的损失的和。</p>
<h1 id="CapsNet架构"><a href="#CapsNet架构" class="headerlink" title="CapsNet架构"></a>CapsNet架构</h1><p>一个简单的CapsNet如图所示，这个架构如此的浅以至于只有两层卷积层和一层全连接层。Conv1是256维，9*9的卷积核，其步长为1和一个Relu激活函数。这个层能够将像素强度转换为特征检测的活动，并且将其作为初级胶囊的输入。</p>
<img src="/2018/01/04/Capsules架构小结/CapsNet_architecture.png" alt="图1" title="图1">
<p>初级胶囊也就是多维实体的最低层，从图像反序列化的角度上来说，初级胶囊对应着反序列化的渲染过程。这比起拼凑实体来组成整体来说，胶囊和他们的工作的方式大不相同。</p>
<p>第二层也是一个卷积胶囊层，其是一个带有32个通道的8维的胶囊。每一个初级胶囊的输出和所有的256*81的卷积单元的输出是一致的。总体的初级胶囊有一个32*6*6的胶囊输出（每一个输出都是一个8维的矢量），每个处于6*6网格中的胶囊共享器权值。对于每一个类，最后的层对应着一个16维的胶囊。</p>
<img src="/2018/01/04/Capsules架构小结/capsule2.png" alt="图2" title="图2">
<p>这篇论文始终都只是针对两层胶囊层。因为conv1的输出都是一维的，所以自然也没有表达空间方向的空间。因此，在conv1和初级胶囊层之间自然也没有路由关系了。斯普皮的路由单元$b_{ij}$也初始化为0，因此，在初始阶段下，一个胶囊的输出就会被<strong>以等概率</strong>传递到所有亲本的胶囊层。在文章之中他也给出了一个tensorfloww的代码实现，并且使用了Adam优化器。</p>
<h2 id="基于正则化的空间信息重建"><a href="#基于正则化的空间信息重建" class="headerlink" title="基于正则化的空间信息重建"></a>基于正则化的空间信息重建</h2><p>我们会使用一个附加的重建损失来让胶囊编码输入数字的实体参数。在训练过程中，我们将会对所有非正确数字的胶囊进行掩码。接下来我们就会使用这个活跃的矢量来重建输入图像。接着数字的胶囊的输出将会被送入一个包含3个全连接层的解码器，这个结构就如图2所示。我们会按照MSE的误差来优化网络。同时我们将会按照0.0005的倍数缩小重建误差，这样在训练的时候其就不会影响到边缘误差。论文中阐释了重建能够很好的还原重要的细节内容。</p>
<img src="/2018/01/04/Capsules架构小结/mnist_capsule.png" alt="图3，在3次路由迭代下的基于CapsNet的MNIST重建" title="图3，在3次路由迭代下的基于CapsNet的MNIST重建">
<table>
<thead>
<tr>
<th>方式</th>
<th>路由次数</th>
<th>是否重建</th>
<th>MNIST(%)</th>
<th>Multi-MNIST(%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Baseline</td>
<td>-</td>
<td>-</td>
<td>0.39</td>
<td>8.1</td>
</tr>
<tr>
<td>CapsNet</td>
<td>1</td>
<td>no</td>
<td>0.34<em>+-0.0032</em></td>
<td>-</td>
</tr>
<tr>
<td>CapsNet</td>
<td>1</td>
<td>yes</td>
<td>0.29<em>+-0.011</em></td>
<td>7.5</td>
</tr>
<tr>
<td>CapsNet</td>
<td>3</td>
<td>no</td>
<td>0.35<em>+-0.036</em></td>
<td>-</td>
</tr>
<tr>
<td>CapsNet</td>
<td>3</td>
<td>yes</td>
<td>0.25<em>+-0.005</em></td>
<td>5.2</td>
</tr>
</tbody>
</table>
<h1 id="Capsule-在MNIST数据集上的表现"><a href="#Capsule-在MNIST数据集上的表现" class="headerlink" title="Capsule 在MNIST数据集上的表现"></a>Capsule 在MNIST数据集上的表现</h1><p>在28*28的MNIST数据下，数据首先被在每个方向以0填充两个像素的策略所处理。这样的话训练集和验证集分别有6w和1w。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2017/11/04/全年小结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/04/全年小结/" itemprop="url">全年小结</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-04T17:04:07+08:00">
                2017-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/反思/" itemprop="url" rel="index">
                    <span itemprop="name">反思</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>不是同一个时间写的。。。见谅</p>
</blockquote>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>自从去年出国就没怎么好好搭理博客了，原来的WordPress难用又卡的没人性，最终还是迁回了Hexo。趁着最近闲的一批，来回顾一下从去年出国到现在的一些感想。</p>
<h1 id="刚到亚琛"><a href="#刚到亚琛" class="headerlink" title="刚到亚琛"></a>刚到亚琛</h1><p>还记得刚到杜塞尔多夫的那一天，干燥而凉爽的风一缕缕从四面八方吹过来，让凌晨刚下飞机的我扫除了所有的困倦，在同学换衣服的间隙，我从口袋里掏出手机，兴奋地插上了SIM卡，在Facebook上发了一条抵达德国的状态。可是时间不允许我做太多的感慨，拽着行李箱，怀揣着3000欧的巨款和对于亚琛的向往，我们笨手笨脚的按照指示牌上的英文到达了杜塞尔多夫机场火车站。由于第一次到达，啥都不了解，应该发成阿亨的<code>Aachen</code>被我直接拿中文的亚琛发出来了，问德国老大爷的时候，老大爷一脸懵逼，大爷在看了地图之后才知道我们的目的地，很热心的指导我们怎么坐车去亚琛（并不像北京的大妈，强迫症式的教你正宗中国话）。我们在一番寒暄之后，列车呼啸着开进了车站。迈着轻快的脚步，我们跳上了去亚琛的车。</p>
<img src="/2017/11/04/全年小结/my_mates.jpg" alt="我的随行同学" title="我的随行同学">
<p>一路上，伴着些许的倦意，我兴奋的抵在列车的舷窗旁看着沿途的风景。我总认为国外都应该是高楼大厦鳞次栉比，然而当列车冲出杜塞没几分钟，大片的绿地就摊在我的眼前，要不是偶尔的电线杆和房屋略过，我都以为已入无人之地。兴奋劲很快如潮水退去后，我们开始了一些寒暄，然后我意识到了一个很大的问题 – 我们在亚琛可能无家可归。然而这个想法并没有在我的脑袋里停留多久就消失了，后来证明，我还是too naive。</p>
<p>天色逐渐泛光，然而雾色四起。列车如离弓的箭穿破蒙蒙的远方，我们在车厢里兴奋地谈论着对未来的预期，时间没有过多久，就来到了Aachen Hauptbahnhof（亚琛主火车站）。刚下火车，我越过深蓝的站牌，穿过阴暗的地下通道，走出火车站的大门，一个宁静的小镇张开了它的翅膀，两旁的鸽子慵懒的迈着步伐，澄澈的阳光紧紧的黏在了我所望各处，这也许就是我对于宁静的最佳的向往吧。</p>
<img src="/2017/11/04/全年小结/AachenHbf.jpg" alt="亚琛主火车站" title="亚琛主火车站">
<p>然而一辆笨拙的公交缓缓的停在了车站旁边，轻轻地歪斜着车体，行人们像溪水汇入山谷一样，逐渐的挤满了车门，于是宁静瞬间变得不那么宁静起来了。多亏同学的机智，早早地就在旅店里订了入住的票，在一番七嘴八舌的流程后，我们便住进了一个青年旅社，在放置好一些东西之后，我们便出了门，在搭上了的免费公交，走走停停后，和妹子的室友碰了头。</p>
<p>随行的妹子的室友，后来也被我称为学姐。学姐身穿一件非常纯色的衣服，静静地站在阳光下，远处的蓝色的楼和学姐相比起来，显得学姐不那么北方，学姐朝着我们挥手并且笑着，我们便毫不费劲的从人群中找到了她。当我们下了站台后，亚琛的阳光才正儿八经的和我打了个照面，在一番简短的寒暄之后，我们便到了学姐的家作客。学姐的家在一个小巷中间楼层的顶楼上，在爬上楼梯后，一个类似鸽子窝那样的空间便呈现在我面前，我不由得感叹房间的袖珍。在同行的妹子放好行李后，我们便动身前往了在图书馆前面的一条街，享受了第一顿在德国的大餐，按照我老妈的话来说，标准的致胖食品。</p>
<img src="/2017/11/04/全年小结/streetOfAachen.jpg" alt="亚琛的街道" title="亚琛的街道">
<p>在得知糖要马不停蹄地去看房子之后，租房子这个问题正式的浮出了水面。由于唐要去看房子，我们便漫无目的的走在亚琛SuperC附近的小道里等着唐回来。亚琛的小道蜿蜒曲折，就好像人的肠道一样，一阵阵风吹过，峭立枝头的黄叶纷纷落下，更加深了这种感觉。我沿路一边漫不经心地踢着路旁卷成球的落叶，一边皱着眉头滑着手机，脑门上的眉毛都要挤到一起了。也不知道过了多久，我在人在亚琛上看到了租房子的帖子，当时我也不知道怎么的，就突然跳了起来，然后以点燃鞭炮然后飞奔的速度，加上了房东。在一番简短的查户口式的寒暄之后，我们约好了和房东见面的时间。当时我依然记得一片落叶伴着和煦的微风，从我脸上扶摇而下的场景，我原本以为那是留学之旅中的来自幸运的礼物，然而，这份礼物却早已在暗中标好了价格。</p>
<img src="/2017/11/04/全年小结/Kaiserplatz.jpg" alt="Kaiserplatz" title="Kaiserplatz">
<p>心腹之患解决之后，剩余的闲晃便变得轻快起来，仿佛失去了地心引力一样，我轻快的走在了亚琛的小路旁，顺便造访了我们认为是以后要工作的流体力学所。然而过了一会，唐看完房子便回了，在简要的交换了消息之后，在得知德国国庆节商店依然休息的消息后，我们便去了REWE买了点明天和德国国庆节的东西。然后便回了学姐家，开了我们在德国的第一顿饭。</p>
<img src="/2017/11/04/全年小结/fulidDynamicsDepartment.jpg" alt="亚琛流体力学所" title="亚琛流体力学所">
<p>我和白在一旁洗了皮，切了水果后，唐便三下五除二的做完了几道菜，在互相吹捧了一番手艺之后，我们吃完了在德国的第一顿自己做的饭，先开始我还有点抱怨唐从国内带来的火腿肠，然而后来证明，我真的很想念火腿肠的滋味。在洗碗盘子和一阵寒暄后，我放好了一些贵重的东西在学姐家，便趁着火车票还能免费做公交的时间，坐上了回青年旅社的公交。回到了旅店，我本以为我还能刷会手机，然而事实证明，我错了，8点才刚过一点点，在生物钟的强大作用下，我便缩起头，闷在被子里就睡着了。</p>
<img src="/2017/11/04/全年小结/banhofScenery.jpg" alt="主火车站的风景" title="主火车站的风景">
<p>第二天早早的就到了，6点钟我就本能的从德国异常柔软的床上睁开了眼，窗外的灯光渐渐隐去，远方的天际线上些微的漏着白光，我随机的在被子里摸索着我的手机，发现还是6点之后，我便翻了个身，继续睡了下去。到了8点，随行的同学便把我叫醒，我才发现对面原本空空如也的上下床睡着个两个大活人，经过一番蹑手蹑脚的洗脸刷牙之后，我们便趁着天光，按照Google Maps给出的路径，穿插在亚琛的迷宫似的小路里，到了学姐的家，吃了一顿我人生中最冰冷的早餐，我不由得想念起家里的热干面、糊汤粉和馄饨，甚至西安的包子的香味也被我从脑海里挖出来了。在早上的随意插科打诨之后，到了中午，吃了午饭，我们便请求学姐和我们同去和房东见面，在一番差强人意的找路之后，我们便在Schibenstrasse的十字路口见到了我们的房东。</p>
<h1 id="与房东的见面"><a href="#与房东的见面" class="headerlink" title="与房东的见面"></a>与房东的见面</h1><p>房东是一个中年的华人，显得并不是很年老，大概45左右的样子，时间好像一把锋利的刀刃，在他的脸上画下了细细的斜纹，在他尖桃型的脸上显得尤其明显，但是头发却还很旺盛。我们和学姐看了房子，房子在一楼，整体显得比较陈旧而杂乱，四角发黑的地毯和零星的菜叶子耷拉在地上，昏黄的灯光简单的勾勒出了房间的样子，浴缸里蒙着一层薄薄的白色粉末，但是整体来说，应有尽有吧。在一番涉及到细节的询问之后，也许是学姐非常的能说会道，房东很爽快的同意了我们的入住，可以说房子这个大石头终于落地了。于是我们就哼着小曲回到了学姐的家。我本以为一天就能这样愉快的过去，然而，房东在下午的时候，一条微信却又要我们帮他买面粉和猪肉，冠冕堂皇的说要锻炼我们的德语。当我收到这个微信的时候，心里真的是仿佛日了狗一样。房东理应清楚我们初入德国，并不理解德文，但是他家又离Netto很近，完全就是变相的占我们的便宜。同行的同学似乎并不是很满意的样子，于是我一个人出了门，路上碰到了学姐，然后在学姐的帮助下，买好了房东要的面粉和猪肉。叫上了同学之后，去了房东的家，房东很爽快了收了买的东西，然后就没下文了。这确实隐隐的让我担心了起来。</p>
<p>在接下来的几天，我们找了一家临时的民俗安顿了一下。在学校SuperC报道之后，我们就去了市政厅办理了注册。在注册的时候，因为房东当时填的登记表的问题，我们联系到他来了市政厅，他显得很慌张，开始道出了他是二房东，然而市政厅人员就淡淡的修正了问题，我们就成功办理了登记注册。随后，就是一些其他的事情了。期间办理了银行卡和亚琛工大的注册，顺便在研究所里见了个面，外国人的脸长得太像。在有可能换到学长作为导师的希望破灭之后，我和唐的导师大抵也定下来了。</p>
<p>房东在注册那天之后就回国了。走之前的前天，以一种软性的提示，让我尝他的包子。虽然我对包子并不讨厌（旺园楼下的老台门真的好评如潮），但是我相当的反感别人强迫我去做事情，我就以一种我不爱吃包子的态度对待这个事情，后来收获了房东认为我不诚实的评价。这可能是我有生之年系列了吧。之后进行了一系列的自我吹捧，“南昌的航空最棒了”等等。起先我还想置喙一二句，但是随后我也有点疲倦了，以一种弱智式的“原来如此”结束了晚间的冗长的谬误。随后，我们在实验室见了导师，导师是一个微胖的马来西亚人，浓浓的眉毛要不是没有他那张脸，我真的就认为是蜡笔小新了。简要的描绘了我们接下来的工作后，我们就愉快的开启了毕设的起点。</p>
<h1 id="亚琛闲逛"><a href="#亚琛闲逛" class="headerlink" title="亚琛闲逛"></a>亚琛闲逛</h1><p>期间我们也在筹谋接下来住哪的问题，在一个不愉快的放鸽子出现之前，一切都还是很愉快的。我们去了ZuseLab上了课，发现了一条非常带感的路。期间我也成功的做出了人生中最完美的一道菜，有很多愉快。并且在当时最值得庆幸的是，我们找到了一个同在一个研究所的学长租了之后的房子。</p>
<img src="/2017/11/04/全年小结/zuselabRoad.jpg" alt="ZuseLab山后的小树林" title="ZuseLab山后的小树林">
<img src="/2017/11/04/全年小结/yellowLeaf.jpg" alt="黄叶和同学" title="黄叶和同学">
<img src="/2017/11/04/全年小结/potatoWithBeefSuccessful.jpg" alt="一次成功的土豆烧牛肉" title="一次成功的土豆烧牛肉">
<img src="/2017/11/04/全年小结/cafertiria.jpg" alt="亚琛食堂" title="亚琛食堂">
<h1 id="科隆之旅"><a href="#科隆之旅" class="headerlink" title="科隆之旅"></a>科隆之旅</h1><p>毕设的起点当然是到处浪了，我们仨第一站就去了科隆。早上离开亚琛的时候，亚琛的天空闪烁着蔚蓝的光，阳光和煦的抛向了四面八方，仿佛跟不要钱一样的（到深冬的时候才知道光明是多么珍贵）。列车离开亚琛没有多久，越过远方一排排成列的电线杆，划过一个个透进缝隙的阴影，突然转过了一个弯，我们便投入了迷雾的怀抱，仿佛无穷无止，迷雾一层叠着一层，一层隐着一层，随意的出现在不同时刻的风景里。我看着手机上的地图，小点沿着细细的线朝科隆的方向蠕动着。逐渐的，雾色渐渐的退到一排排像乳牙一般的房子后，科隆到了。</p>
<p>科隆火车站整体来说比亚琛高到不知道哪里去了，拥挤的人群，嘈杂的声音都无时不刻的提醒着我们到了“大城市”。沿着人流的方向，我们纵越而出，当寒冷的空气带走我脸上的湿气之前，一个偌大的教堂就站在我们的面前。仿佛一座山一样的震撼，科隆大教堂就这样映入我的眼帘。高耸的尖顶直插雾色蒙蒙的天空里，雾气缓缓的拂过教堂外墙壁上的装饰，浮雕若隐若现的站在高高的墙上，向远方眺望着来自西边的风。我讶异于此情此景，一时呆在台阶上，不知所云。在猴急一般的按下手机的快门后，我们进了教堂内部参观。仿佛进入人体的内脏一般，整个教堂显得十分的晦暗，窗上的彩色玻璃透出的一缕缕微光构成了一幅幅马赛克式的图画，更显得教堂的仪式感的强烈。我感到一阵头皮发麻，在小鸡啄米式的参观完之后，我便朝着最光亮的地方走去，离开了教堂。</p>
<img src="/2017/11/04/全年小结/KolnGreatChurch.jpg" alt="科隆大教堂" title="科隆大教堂">
<img src="/2017/11/04/全年小结/allOfUs.jpg" alt="合照" title="合照">
<p>然后我们走在科隆的大街小巷里，路旁偶尔传来的中国大妈旅行团的乡音无疑是对我们这次旅行最大的慰藉了。雾色渐渐的消隐，一个明亮的科隆就这样展现在我们的眼前，偶尔从墙头另一头满的溢出来的红叶随着微风舞动，都使得这次旅程倍增生气。在唐合了照以后，一条似臂弯的大河就突然抚平了我们眼前的杂乱，直直的冲着我们溜过来，却又奔涌地离开。深秋的莱茵河泛着青色的光芒，河水舔舐着坑坑洼洼的堤岸，发出莎莎的声音，仿佛高考前撕书的时候那阵莫名其妙的舒爽，我的心仿佛静止在这一刻，静止在平静的河水之上。忽然，一阵哐当哐当的声音从头顶跺着脚经过，一列火车碾压者饱经风霜的小桥，欢快的开向了青色的彼岸。我上了桥，在谴责了一阵恋爱的腐臭味之后，便朝着巧克力工厂走去。巧克力工厂就在堤岸朝河中心延伸的一个高地上，我们在里面参观了从可可豆的摇篮到坟墓的全过程，顺便站在似船头的屋顶眺望了整个科隆城。也许是亚琛呆了一个月习惯了吧，科隆竟让我嗅到了一股大城市的味道，现在想起来都不免的讪讪的发笑。接下来，我们薅了一波学生票的羊毛，坐着免费的轻轨去了科隆的能源足球场，能源足球场坐落在一片小树林里，在从城铁站到体育馆的路上，绵密的树穿插交结在我们的头顶，脚下还没腐烂彻底的红叶和黄叶沾着泥土，前俯后仰的扑向了体育馆。刚到体育馆的时候，眼前除了大片大片的草地就是体育馆了，我不由得感慨发达国家的草坪就跟不要钱一样。绕了一圈，除了偶尔出现在路牌闪着光的碎酒瓶以外，似乎也没有什么能让我兴奋的了。在围观了一群业余球员在足球场上踢了一会后，伴着刚从云层里闪耀而出的阳光，我们回到了科隆主火车站。也许是累了，一路上，我们仨都显得很沉默，就这样我们回了亚琛。</p>
<img src="/2017/11/04/全年小结/redLeaf.jpg" alt="红叶疯了" title="红叶疯了">
<img src="/2017/11/04/全年小结/baiWithBridge.jpg" alt="小白和桥" title="小白和桥">
<img src="/2017/11/04/全年小结/IAndCandy.jpg" alt="抱着糖的我" title="抱着糖的我">
<img src="/2017/11/04/全年小结/kolnGym.jpg" alt="科隆能源体育场" title="科隆能源体育场">
<h1 id="帮学长搬家"><a href="#帮学长搬家" class="headerlink" title="帮学长搬家"></a>帮学长搬家</h1><p>过了几天，即将可能同租的学长要求我们去帮他搬家，之前他还夸夸自谈自己如何的friendly，结果搬家的时候却是茕茕孑立，说好的黄学长也没到，却是显得很讽刺。同住的同学忙于考试，表示不愿意去帮忙。本来我也是非常讨厌别人强迫我去做我不愿意的事情，但是鉴于以后可能无房可住，我也只能为五斗米折腰了。深秋的亚琛，街上晃荡着冷冷的微风，我紧着身子，在Kaiserplatz寥寥无几的站牌上等了一会后，公交灵敏的穿梭过窄窄的街道，我便一个鹞子翻身一样，跳上了公交。车行在深秋的亚琛，路旁的树是不是摇曳着身体，乘着嘶嘶的小风，金黄的树叶簌簌而下，深秋的寒意就这样散漫在空气里。到达了Aachen West，迟暮的日光低悬在西方的天空，染黄了其所及之处，我在学长的搬离之处等了好一会，终于上了他的楼帮他搬家。不得不说他之前住的地方比学姐的家更加的小了，灶台和床都拥挤的挤在一起，我觉得能下脚的地方不超过一平方米，我笨拙的找了个位置站了之后，便开始了帮他搬运东西。他起初对于同学未至表示了理解，并且说了一些地域歧视的话。作为一名保守的南方人，地域歧视本身我也是识得多的了，但是个人感觉这个并不足以成为地域歧视的基点。在转移话题后，我帮他搬了一张桌子。他的新家和老家离得并不是很远，大概两站路的样子，我们便走在了昏黄的亚琛街头。离开了他家，一股清新的空气便扑鼻而来，路上，学长借由同学的缺席开始找我们要价，提出了涨价的要求。我以时间不成熟为由，提出考虑一下。其实我心里认为的是，搬家毕竟不是我们必要的，况且我本人已经到了，你不给我们补贴也就算了，还借机涨价，并且我本人算是个准黑户，我觉得学长做的根本就是不可理喻。仿佛是亚琛的惯例一样，我又被查了一次户口，由于对于寒冷的本能厌恶，我随口说了很多信息，至于哪个是对的，哪个是错的，恐怕只有亚琛的风知道。然而当我问他相同的问题的时候，他却以一种非常弱智的口吻来让我猜。直觉本能的告诉我，这个绝对是一个深坑。</p>
<p>在一番搬家完成之后，他笑着说我搬得多，借机又嘲讽了一顿南方人。也许是麻木了，我笑了笑就翻了这一页。可是学长并没有因此结束他冗长的谈论，他借着同学没来为由，借机对我们的入住规定了条条框框。我大概的回忆了一下，大概就是</p>
<ul>
<li>可能蹭饭</li>
<li>需要我们清理卫生间</li>
<li>所有家具归他</li>
<li>需要我们走之前找好舍友</li>
<li>我必须当黑户</li>
</ul>
<p>我觉得这些根本就不可理喻，我提出了我可能要去haren找房子为由，没有回应他的要求。他又以那一套为你好的话来搪塞我，我也就没说啥。终于在一番不可言状的交谈后，我便离开了那个地方。出了门，仿佛是气球泄了气，我便跑到了公交站牌，我便打定了主意，不准备和学长同租了。回到了家，我原本以为同学还在对学长的不可理喻愤怒，然而他心情已经平复了，相反我还处在对学长的愤怒之中，我也不知道那天之后发生了什么。也许是对他提出要求的最后一条的深刻怀疑，我暗中下定了决心，我要自己找房子租住。</p>
<p>之后他又找我一起去看窗帘，他一直纠结于贵价的窗帘，在一番他仔细斟酌后，在一番讽刺我买的最便宜的窗帘后，便要求试用我买的便宜的窗帘，我想都没想就打发了他。真的我已经麻木了。不得不说他真的是强，烦我从天亮到天黑。</p>
<img src="/2017/11/04/全年小结/Aachen_west_sunset.jpg" alt="亚琛西的日落" title="亚琛西的日落">
<img src="/2017/11/04/全年小结/POCO_sunset.jpg" alt="POCO的日落" title="POCO的日落">
<h1 id="波恩之行"><a href="#波恩之行" class="headerlink" title="波恩之行"></a>波恩之行</h1><p>我们选择了去西德首都波恩，也许是来自科隆的震撼未消，波恩的火车站显得非古天乐式的平平无奇了。爽朗的阳光，浅蓝的天空，低矮的房子，构成了我对于波恩的第一印象，我们参观完贝多芬故居，前市政厅之后便临了了。</p>
<p>期间发生了我认为一件很不愉快的事情，不得不说在有些事情上，可能大家都是受害者吧。也许有一天那一天会走远，也许我对于外婆的记忆中不掺有任何的仇恨，也许有一天我可以走出那篇阴云，也许有一天我能忘却那个无法逃避的夜晚。希望有些东西能够消逝吧，但是，还是希望有一天公正会到来，会将至，会让逝者长眠，让生者平淡。</p>
<p>波恩的一天最后还是以满意结束了，很不错的小镇，符合我对宁静的完美定义。</p>
<img src="/2017/11/04/全年小结/boenCityHall.jpg" alt="boenCityHall.jpg" title="">
<img src="/2017/11/04/全年小结/boenRail.jpg" alt="boenRail.jpg" title="">

<img src="/2017/11/04/全年小结/boenBuildings.jpg" alt="boenBuildings.jpg" title="">
<h1 id="蒙绍"><a href="#蒙绍" class="headerlink" title="蒙绍"></a>蒙绍</h1><p>波恩之后就是蒙绍了，蒙绍坐落在北威州的西南角，我们在Bushof坐了足足一个多小时才到。此时德国已经进入冬天，路上信号时隐时现，时而穿插的白雪时不时的投影在模糊的窗户上，料峭的天光隐隐约约穿越树枝穿插而成的缝隙，寒冷这两个词就像不断交错的光影一样，刷新着我的记忆。刚下公交，好像夏天打开冰箱一样的舒爽，蒙绍就这样走进了我的视线之中。走进窄窄的箱子，周围张扬的颜色掠过我的头顶，耳边潺潺的流水轻轻呢喃，路边的窗户上映射出别样的风光，仿佛时间就凝结于这里。在行云流水般结束之后，我们顺着铺满黄叶的山坡，一脚一脚的爬上了山坡。顺着和煦的微风，目光被投射到山谷里的蒙绍。仿佛入梦一般，蒙绍的建筑矗立在淡雾之中，显得越发的迷人。在山坡上，被细细的山路切割的田地在阳光的反射下呈现出异样的光芒，马安安静静的咀嚼着葱绿的小草。一切如行云流水般，让我静止于光与影，诗和歌的远方。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2017/08/14/如何更好的构建GAN网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/14/如何更好的构建GAN网络/" itemprop="url">如何更好的构建GAN网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-14T14:55:03+08:00">
                2017-08-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>全文整理自知乎<a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="external">令人拍案叫绝的Wasserstein GAN</a></p>
</blockquote>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>GAN（生成对抗网络）自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。</p>
<h1 id="Wasserstein-GAN"><a href="#Wasserstein-GAN" class="headerlink" title="Wasserstein GAN"></a>Wasserstein GAN</h1><p>实际上作者整整花了两篇论文，在第一篇<a href="https://arxiv.org/abs/1701.04862" target="_blank" rel="external">《Towards Principled Methods for Training Generative Adversarial Networks》</a>里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇<a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="external">《Wasserstein GAN》</a>里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程</p>
<ul>
<li>判别器最后一层去掉sigmoid</li>
<li>生成器和判别器的loss不取log</li>
<li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li>
<li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li>
</ul>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：</p>
<ul>
<li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度</li>
<li>基本解决了collapse mode的问题，确保了生成样本的多样性 </li>
<li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示）</li>
<li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li>
</ul>
<h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><p><img src="GAN_optimize_algorithm.jpg" alt="GAN的优化算法"></p>
<h1 id="原始的GAN的问题"><a href="#原始的GAN的问题" class="headerlink" title="原始的GAN的问题"></a>原始的GAN的问题</h1><p>原始GAN中判别器要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例：</p>
<p>$$ -\mathbb{E}_{x\sim P_r}[\log D(x)] - \mathbb{E}_{x\sim P_g}[\log(1-D(x))] $$</p>
<p>其中\(P_{r}\)是真实样本分布， \(P_g \)是由生成器产生的样本分布。对于生成器，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是</p>
<p>$$ \mathbb{E}_{x\sim P_g}[\log(1-D(x))] $$</p>
<p>$$ \mathbb{E}_{x\sim P_g}[- \log D(x)] $$</p>
<h2 id="第一种原始GAN形式的问题"><a href="#第一种原始GAN形式的问题" class="headerlink" title="第一种原始GAN形式的问题"></a>第一种原始GAN形式的问题</h2><p><strong>一句话概括：判别器越好，生成器梯度消失越严重</strong>。WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。</p>
<p>首先从公式1可以得到，在生成器G固定参数时最优的判别器\(D\)应该是什么。对于一个具体的样本x，它可能来自真实分布也可能来自生成分布，它对公式1损失函数的贡献是</p>
<p>$$ - P_r(x) \log D(x) - P_g(x) \log [1 - D(x)] $$</p>
<p>令其关于D(x)的导数为0，得</p>
<p>$$ - \frac{P_r(x)}{D(x)} + \frac{P_g(x)}{1 - D(x)} = 0 $$</p>
<p>化简得最优判别器为：</p>
<p>$$ D^*(x) = \frac{P_r(x)}{P_r(x) + P_g(x)} $$</p>
<p>这个结果从直观上很容易理解，就是看一个样本x来自真实分布和生成分布的可能性的相对比例。如果\(P_r(x) = 0\)且\( P_g(x) \neq 0 \)，最优判别器就应该非常自信地给出概率0；如果\(P_r(x) = P_g(x)\)，说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。</p>
<p>然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成</p>
<p>$$\mathbb{E}_{x\sim P_r}[\log D(x)] + \mathbb{E}_{x\sim P_g}[\log(1-D(x))]$$</p>
<p>注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到</p>
<p>$$\mathbb{E}_{x \sim P_r} \log \frac{P_r(x)}{\frac{1}{2}[P_r(x) + P_g(x)]} + \mathbb{E}_{x \sim P_g} \log \frac{P_g(x)}{\frac{1}{2}[P_r(x) + P_g(x)]} - 2\log 2$$（公式5)</p>
<p>变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：</p>
<p>$$KL(P_1||P_2) = \mathbb{E}_{x \sim P_1} \log \frac{P_1}{P_2}（公式6）$$</p>
<p>$$JS(P_1 || P_2) = \frac{1}{2}KL(P_1||\frac{P_1 + P_2}{2}) + \frac{1}{2}KL(P_2||\frac{P_1 + P_2}{2})（公式7）$$</p>
<p>于是公式5就可以继续写成</p>
<p>$$2JS(P_r || P_g) - 2\log 2（公式8）$$</p>
<p>到这里读者可以先喘一口气，看看目前得到了什么结论：根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g 之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化 P_r 和P_g之间的JS散度。</p>
<p>问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小，我们通过优化JS散度就能将\( P_g \)“拉向”\( P_r \)，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略，它们的JS散度是多少呢？</p>
<p>答案是\(\log 2\)，因为对于任意一个x只有四种可能：</p>
<p>$$P_1(x) = 0且P_2(x) = 0$$</p>
<p>$$P_1(x) \neq 0且P_2(x) \neq 0$$</p>
<p>$$P_1(x) = 0且P_2(x) \neq 0$$</p>
<p>$$P_1(x) \neq 0且P_2(x) = 0$$</p>
<p>第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是\(\log \frac{P_2}{\frac{1}{2}(P_2 + 0)} = \log 2\)，第四种情况与之类似，所以最终\(JS(P_1||P_2) = \log 2\)。</p>
<p>换句话说，无论\( P_r\)跟\(P_g\)<br>是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数\(\log 2\)，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2017/08/09/使用Keras建立对抗生成网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/09/使用Keras建立对抗生成网络/" itemprop="url">使用Keras建立生成对抗网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-09T00:35:13+08:00">
                2017-08-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>生成对抗网络（英语：Generative Adversarial Network，简称GAN）是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。该方法由扬·古德费洛等人于2014年提出。</p>
<p>生成对抗网络由一个生成网络与一个判别网络组成。生成网络从潜在空间（latent space）中随机采样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。</p>
<p>虽然说GAN听起来很简单，但是要构建这样的一个模型却不是那么轻而易举。在GAN之中，有两个相关联的深度网络，当训练的时候他们都会发生梯度的反向传播。深度卷积生成对抗网络（Deep Convolutional GAN）就是这样一种典型的GAN。</p>
<p>在这篇文章之中，我们会介绍如何通过Keras构建一个DCGAN。我们将会利用它来学习如何编写一个手写的数字，就好像MNIST数据集一样。</p>
<h1 id="判别网络"><a href="#判别网络" class="headerlink" title="判别网络"></a>判别网络</h1><p>判别网络能够很好的判断图片是否是一个真实的图像，如图所示，其也就是一个很常见的卷积神经网络。对于MNIST数据库，其驶入就是一张28*28*1的图片。最终的sigmoid激活函数是告诉这张图片是真实的图片的概率。这个和典型的CNN模型最大的区别就是在层与层之间判别网络丢失了池化层。这个时候，一个有步长的卷积就用来下采样了。在每个CNN层使用的激活函数是leaky Relu函数（LeakyRelU是修正线性单元（Rectified Linear Unit，ReLU）的特殊版本，当不激活时，LeakyReLU仍然会有非零输出值，从而获得一个小梯度，避免ReLU可能出现的神经元“死亡”现象。即，$$f(x)=alpha * x for x &lt; 0$$  $$f(x) = x for x&gt;=0$$）。为了阻止过拟合，Dropout层被使用了</p>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANdiscriminator.png" alt="判别网络" title="判别网络">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DCGAN</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,img_rows=<span class="number">28</span>,img_cols=<span class="number">28</span>,img_channel=<span class="number">1</span>)</span>:</span></div><div class="line">        self.img_rows = img_rows</div><div class="line">        self.img_cols = img_cols</div><div class="line">        self.img_channel = img_channel</div><div class="line">        self.D = <span class="keyword">None</span>  <span class="comment"># discriminator</span></div><div class="line">        self.G = <span class="keyword">None</span>  <span class="comment"># generator</span></div><div class="line">        self.AM = <span class="keyword">None</span>  <span class="comment"># adversarial model</span></div><div class="line">        self.DM = <span class="keyword">None</span>  <span class="comment"># discriminator model</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self,depth=<span class="number">64</span>,dropout=<span class="number">0.5</span>,cnn_layers_num=<span class="number">4</span>)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.D:</div><div class="line">            <span class="keyword">return</span> self.D</div><div class="line">        self.D = Sequential()</div><div class="line">        <span class="comment"># In: 28 * 28 * 1, depth = 1</span></div><div class="line">        <span class="comment"># Out: 14 * 14 * 64, depth = 64</span></div><div class="line"></div><div class="line">        input_shape = (self.img_cols,self.img_rows,self.img_channel)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(cnn_layers_num):</div><div class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">                self.D.add(Conv2D(depth*<span class="number">2</span>**<span class="number">0</span>,<span class="number">5</span>,strides=<span class="number">2</span>,padding=<span class="string">'same'</span>,activation=LeakyReLU(alpha=<span class="number">0.2</span>),</div><div class="line">                                  input_shape=input_shape))</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                self.D.add(Conv2D(depth * <span class="number">2</span> ** <span class="number">0</span>, <span class="number">5</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, activation=LeakyReLU(alpha=<span class="number">0.2</span>)))</div><div class="line"></div><div class="line">            self.D.add(Dropout(dropout))</div><div class="line"></div><div class="line">        self.D.add(Flatten())</div><div class="line">        self.D.add(Dense(<span class="number">1</span>))</div><div class="line">        self.D.add(Activation(<span class="string">'sigmoid'</span>))</div><div class="line">        self.D.summary()</div><div class="line">        <span class="keyword">return</span> self.D</div></pre></td></tr></table></figure>
<h1 id="生成网络"><a href="#生成网络" class="headerlink" title="生成网络"></a>生成网络</h1><p>生成网络则是为了生成虚假的图片的。在下图里，虚假的图片会从一个100维的噪声中生成（噪声均部于-1.0至1.0之间）。这里我们使用了一个对卷积求逆的操作，也称为反卷积（需要反卷积的情况通常发生在用户想要对一个普通卷积的结果做反方向的变换。例如，将具有该卷积层输出shape的tensor转换为具有该卷积层输入shape的tensor。同时保留与卷积层兼容的连接模式）。不同于在DCGAN之中分别步长求卷积，因为生成网络需要生成更加符合实际情况的手写图片，所以在前三层之中上采样都被使用。在每层网络之间，样本规范也被使用来使得学习变得稳定。每个层的激活函数就是Relu。最终激活函数sigmoid的输出就是虚假的图片。最开始的Dropout层的断开率取在0.3到0.5之间。</p>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANgenerator.png" alt="生成网络" title="生成网络">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,momentum=<span class="number">0.9</span>)</span>:</span></div><div class="line">    <span class="keyword">if</span> self.G:</div><div class="line">        <span class="keyword">return</span> self.G</div><div class="line">    self.G = Sequential()</div><div class="line">    dropout = <span class="number">0.4</span></div><div class="line">    depth = <span class="number">64</span> * <span class="number">4</span></div><div class="line">    dim = <span class="number">7</span></div><div class="line">    <span class="comment"># In: 100</span></div><div class="line">    <span class="comment"># Out: dim x dim x depth</span></div><div class="line">    self.G.add(Dense(dim * dim * depth, input_dim=<span class="number">100</span>))</div><div class="line">    self.G.add(BatchNormalization(momentum=momentum))</div><div class="line">    self.G.add(Activation(<span class="string">'relu'</span>))</div><div class="line">    self.G.add(Reshape((dim, dim, depth)))</div><div class="line">    self.G.add(Dropout(dropout))</div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">        self.G.add(UpSampling2D())</div><div class="line">        self.G.add(Conv2DTranspose(int(depth / <span class="number">2</span>**(i+<span class="number">1</span>)), <span class="number">5</span>, padding=<span class="string">'same'</span>))</div><div class="line">        self.G.add(BatchNormalization(momentum=<span class="number">0.9</span>))</div><div class="line">        self.G.add(Activation(<span class="string">'relu'</span>))</div><div class="line"></div><div class="line">    <span class="comment"># Out: 28 * 28 * 1</span></div><div class="line">    self.G.add(Conv2DTranspose(<span class="number">1</span>,<span class="number">5</span>,padding=<span class="string">'same'</span>))</div><div class="line">    self.G.add(Activation(<span class="string">'sigmoid'</span>))</div><div class="line">    self.G.summary()</div><div class="line">    <span class="keyword">return</span> self.G</div></pre></td></tr></table></figure>
<h1 id="GAN模型"><a href="#GAN模型" class="headerlink" title="GAN模型"></a>GAN模型</h1><p>到现在为止，我们还没有生成模型。那么现在我们就动手构建训练用的模型吧。我们需要辨别和生成模型。</p>
<h2 id="辨别模型"><a href="#辨别模型" class="headerlink" title="辨别模型"></a>辨别模型</h2><p>下面就显示了如何生成辨别模型的keras代码。由于我们使用了sigmoid作为激活函数，所以我们使用了<strong>对数损失</strong>作为损失函数。<strong>RMSProp</strong>作为优化器比起Adam来说能生成更实际的虚假图像。这里的学习率是<strong>0.0008</strong>。权重的decay和梯度的削减将会在接下来的训练中使得学习过程变得稳定化。decay需要随着调整学习率进行相应的调整。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator_model</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">if</span> self.DM:</div><div class="line">        <span class="keyword">return</span> self.DM</div><div class="line">    optimizer = RMSprop(lr=<span class="number">0.0002</span>, decay=<span class="number">6e-8</span>, clipvalue=<span class="number">1.0</span>)</div><div class="line">    self.DM = Sequential()</div><div class="line">    self.DM.add(self.discriminator())</div><div class="line">    self.DM.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=optimizer, \</div><div class="line">                    metrics=[<span class="string">'accuracy'</span>])</div><div class="line">    <span class="keyword">return</span> self.DM</div></pre></td></tr></table></figure>
<h2 id="对抗模型"><a href="#对抗模型" class="headerlink" title="对抗模型"></a>对抗模型</h2><p>对抗网络就像是生成网络和辨别网络铺垫如图所示。生成器尽力去欺骗辨别器并且同时习得反馈的内容。其他的部分和辨别模型一致，只不过减小了学习率和对应的权重的decay。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adversarial_model</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">if</span> self.AM:</div><div class="line">        <span class="keyword">return</span> self.AM</div><div class="line">    optimizer = RMSprop(lr=<span class="number">0.0001</span>, decay=<span class="number">3e-8</span>, clipvalue =<span class="number">1.0</span>)</div><div class="line">    self.AM = Sequential()</div><div class="line">    self.AM.add(self.generator())</div><div class="line">    self.AM.add(self.discriminator())</div><div class="line">    self.AM.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=optimizer,metrics=[<span class="string">'accuracy'</span>])</div><div class="line">    <span class="keyword">return</span> self.AM</div></pre></td></tr></table></figure>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANadversarialmodel.png" alt="对抗模型" title="对抗模型">
<h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><p><strong>对抗生成网络的训练强烈建议在较强的GPU下进行！</strong></p>
<p>训练就是最困难的部分了。我们需要先确定辨别器是否能够单独辨别真实以及虚假的图片。接下来，辨别器和对抗网络一个接着一个的训练。图片也显示了这个过程。</p>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANtraining.png" alt="训练" title="训练">
<p>在训练的过程中固定一方，更新另一方的网络权重，交替迭代，在这个过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到一个动态的平衡（纳什均衡），此时生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。</p>
<p>当固定生成网络 G 的时候，对于判别网络 D 的优化，可以这样理解：输入来自于真实数据，D 优化网络结构使自己输出 1，输入来自于生成数据，D 优化网络结构使自己输出 0；当固定判别网络 D 的时候，G 优化自己的网络使自己输出尽可能和真实数据一样的样本，并且使得生成的样本经过 D 的判别之后，D 输出高概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">images_train = self.x_train[np.random.randint(<span class="number">0</span>,\</div><div class="line">    self.x_train.shape[<span class="number">0</span>], size=batch_size), :, :, :]</div><div class="line">noise = np.random.uniform(<span class="number">-1.0</span>, <span class="number">1.0</span>, size=[batch_size, <span class="number">100</span>])</div><div class="line">images_fake = self.generator.predict(noise)</div><div class="line">x = np.concatenate((images_train, images_fake))</div><div class="line">y = np.ones([<span class="number">2</span>*batch_size, <span class="number">1</span>])</div><div class="line">y[batch_size:, :] = <span class="number">0</span></div><div class="line">d_loss = self.discriminator.train_on_batch(x, y)</div><div class="line"></div><div class="line">y = np.ones([batch_size, <span class="number">1</span>])</div><div class="line">noise = np.random.uniform(<span class="number">-1.0</span>, <span class="number">1.0</span>, size=[batch_size, <span class="number">100</span>])</div><div class="line">a_loss = self.adversarial.train_on_batch(noise, y)</div></pre></td></tr></table></figure>
<p>由于其深度，训练一个GAN模型需要很大的耐心，下面有些需要注意的事宜：</p>
<table>
<thead>
<tr>
<th>问题</th>
<th>方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>生成一个类似于噪声的图像</td>
<td>在辨别器和生成器上使用dropout层，比较低的随机断开率（0.3-0.6之间）就会生成一个比较真实的图像</td>
</tr>
<tr>
<td>辨别器的损失很快的收敛到0使得生成器无法学习</td>
<td>不要预先训练辨别器，而需要使得它的学习率大于对抗网络的学习率。使用一个不同的训练噪声的样本</td>
</tr>
<tr>
<td>生成的图像还是很像噪声</td>
<td>检查激活函数，样本规范层以及随机断开层是否正确的应用于正确的序列之中</td>
</tr>
<tr>
<td>如何获得正确的训练/模型参数</td>
<td>先开始选用一些从论文中已知的结果。在训练2000或更多步之后，每隔500或者1000步之后观察参数的结果</td>
</tr>
</tbody>
</table>
<p>代码参考：<a href="https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan_mnist.py" target="_blank" rel="external">https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan_mnist.py</a></p>
<h1 id="样本的输出"><a href="#样本的输出" class="headerlink" title="样本的输出"></a>样本的输出</h1><p>下图显示了输出图形的进化，后面的图形已经非常完美了。</p>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANsampleresult.png" alt="对抗生成网络的结果" title="对抗生成网络的结果">
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><p>有人反应在1000步之后的图像不甚理想，如下面所示。</p>
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANQA1.png" alt="结果1" title="结果1">
<img src="/2017/08/09/使用Keras建立对抗生成网络/GANQA2.png" alt="结果2" title="结果2">
<p>这是因为GAN对于参数的初始化非常的敏感，这也就是为什么GAN很难应用的原因。参数的参数化在不同的CPU上有不一样的方法。</p>
<h1 id="如何生成视频呢？"><a href="#如何生成视频呢？" class="headerlink" title="如何生成视频呢？"></a>如何生成视频呢？</h1><p>论文见下<a href="https://arxiv.org/abs/1609.02612" target="_blank" rel="external">https://arxiv.org/abs/1609.02612</a></p>
<h1 id="特殊的技巧"><a href="#特殊的技巧" class="headerlink" title="特殊的技巧"></a>特殊的技巧</h1><p>请见博文Wasserstein GAN，里面介绍了如何克服GAN难训练的原因以及解决方法</p>
<h1 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h1><blockquote>
<ul>
<li><a href="https://medium.com/towards-data-science/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0" target="_blank" rel="external">https://medium.com/towards-data-science/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0</a></li>
<li><a href="http://www.cnblogs.com/Charles-Wan/p/6238033.html" target="_blank" rel="external">http://www.cnblogs.com/Charles-Wan/p/6238033.html</a></li>
</ul>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2017/07/08/Ubuntu-16-04-OpenCL-Tensorflow-Keras配置参考/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/08/Ubuntu-16-04-OpenCL-Tensorflow-Keras配置参考/" itemprop="url">Ubuntu 16.04+OpenCL+Tensorflow+Keras配置参考</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-08T21:16:56+08:00">
                2017-07-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>平常正儿八经的拿CPU跑Tensorflow也问题不大，直到最近我跑了一个RNN模型之后，CPU的300+s的一个epoch实在让我无法忍受了，所以痛定思痛的我选择了GPU来跑算法。但是很尴尬的是，我用的是农企的显卡，跑不了主流的CUDA，在经过两三天的配置之后，终于成功的配置好了开启OpenCL支持的Tensorflow了，跑LSTM还是很愉快的。</p>
<h1 id="安装Ubuntu-16-04-LTS"><a href="#安装Ubuntu-16-04-LTS" class="headerlink" title="安装Ubuntu 16.04 LTS"></a>安装Ubuntu 16.04 LTS</h1><p>因为目前农企实质上已经不支持fglrx了，而且对于我的显卡<code>Advanced Micro Devices, Inc. [AMD/ATI] Mars [Radeon HD 8670A/8670M/8750M]</code>来说，fglrx驱动总是一堆问题，所以我果断选择了16.04这个版本。在这个版本，开源驱动被支持，比如<code>Radeon</code>以及<code>AMD GPU Pro</code>。</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>首先你需要安装<code>cmake</code>以及其他编译经常需要的工具。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span># install build essentials</div><div class="line">sudo apt-get install cmake</div><div class="line">sudo apt-get update &amp;&amp; sudo apt-get install build-essential</div></pre></td></tr></table></figure>
<p>接下来需要安装鼎鼎大名的<code>boost</code>以及<code>libssl</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libssl0.9.8:i386</div><div class="line">sudo apt-get install libboost-all-dev</div><div class="line"></div><div class="line">sudo apt-get install libgtest-dev</div><div class="line">cd /usr/src/gtest</div><div class="line">sudo cmake .</div><div class="line">sudo make</div><div class="line">sudo mv libg* /usr/lib/</div></pre></td></tr></table></figure>
<h1 id="安装-Python"><a href="#安装-Python" class="headerlink" title="安装 Python"></a>安装 Python</h1><p>建议使用anaconda来安装Python 3.5。</p>
<p>现在主流的包和库都支持Python 3并且有些库（例如Django）已经明确宣称不支持Python 2，同时，Python 3 对Unicode良好的兼容性对于开发有中文的数据来说，非常省心。</p>
<p>其实这里推荐anaconda的主要原因还是因为<code>Theano</code>。因为如果你想使用带有<code>OpenCL</code>支持的<code>Theano</code>，你就必须使用其后端<code>libgpuarray</code>。而这个包在<code>issue</code>里面明确对不使用<code>conda</code>安装该库的用户提供非常有限的支持。还有一点就是anaconda自带了众多的科学计算库，一步到位确实非常省心。</p>
<h2 id="对不使用anaconda的少年的说明"><a href="#对不使用anaconda的少年的说明" class="headerlink" title="对不使用anaconda的少年的说明"></a>对不使用anaconda的少年的说明</h2><p>对于不想安装anaconda的少年（conda速度真的不多说，推荐使用清华tuna的源），自然我提出一些小小的参考。</p>
<p>你需要安装numpy等一众科学计算的库，你可能还需要安装BLAS、MKL等一系列库以求支持TF。建议知道这些东西的人手工配齐库。</p>
<p>如果遇到问题，百度或者google吧。</p>
<h1 id="安装OpenCL"><a href="#安装OpenCL" class="headerlink" title="安装OpenCL"></a>安装OpenCL</h1><p>就我来说，AMD网上的驱动几乎不能成功。所以我选择了一种非常优雅的方式，apt安装。</p>
<blockquote>
<p>Ubuntu 16.04 has an mesa-opencl-icd package, as well as the libclc-* packages that should be enough to support open source OpenCL on AMD hardware.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo add-apt-repository ppa:paulo-miguel-dias/mesa </div><div class="line"><span class="meta">$</span> sudo apt-get update</div><div class="line"><span class="meta">$</span> sudo apt-get install libclc-amdgcn mesa-opencl-icd</div></pre></td></tr></table></figure>
<h2 id="移除这个PPA"><a href="#移除这个PPA" class="headerlink" title="移除这个PPA"></a>移除这个PPA</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo apt-get install ppa-purge</div><div class="line"><span class="meta">$</span> sudo ppa-purge ppa:oibaf/graphics-drivers</div></pre></td></tr></table></figure>
<p>更多的信息你可以参考这篇博文：<a href="https://laanwj.github.io/2016/05/06/opencl-ubuntu1604.html" target="_blank" rel="external">https://laanwj.github.io/2016/05/06/opencl-ubuntu1604.html</a></p>
<h1 id="为Theano安装的准备"><a href="#为Theano安装的准备" class="headerlink" title="为Theano安装的准备"></a>为Theano安装的准备</h1><p><em>如果你不需要安装Theano，那么你可以跳过这一项，下面这项目会自动引用系统自带的Python，与下面所说的安装Python有所出入。</em></p>
<p><em>Theano sucks</em></p>
<p>为<code>theano</code>的支持安装<code>clblas</code>库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span># clBlas</div><div class="line">sudo apt-get install git</div><div class="line">git clone https://github.com/clMathLibraries/clBLAS.git</div><div class="line">cd clBLAS/</div><div class="line">mkdir build</div><div class="line">cd build/</div><div class="line">sudo apt-cache search openblas</div><div class="line">sudo apt-get install libopenblas-base libopenblas-dev</div><div class="line">sudo apt-get install liblapack3gf liblapack-doc liblapack-dev</div><div class="line">cmake ../src</div><div class="line">make</div><div class="line">sudo make install</div></pre></td></tr></table></figure>
<p>接下来安装libgpuarray</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/Theano/libgpuarray.git</div><div class="line">cd libgpuarray</div><div class="line">mkdir Build</div><div class="line">cd Build</div><div class="line">cmake .. -DCMAKE_BUILD_TYPE=Release -DOPENCL_INCLUDE_DIRS=/opt/AMDAPPSDK-3.0-0-Beta/include</div><div class="line">make</div><div class="line">sudo make install</div><div class="line">cd ..</div><div class="line">sudo apt-get install cython</div><div class="line">sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libopenblas-dev git</div><div class="line">python setup.py build</div><div class="line">sudo python setup.py install</div></pre></td></tr></table></figure>
<p>安装 Theano</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span># Theano</div><div class="line">pip install Theano</div><div class="line">sudo pip install Theano</div></pre></td></tr></table></figure>
<h1 id="安装Tensorflow"><a href="#安装Tensorflow" class="headerlink" title="安装Tensorflow"></a>安装Tensorflow</h1><h2 id="安装computeCPP"><a href="#安装computeCPP" class="headerlink" title="安装computeCPP"></a>安装computeCPP</h2><p>这个库真的挺奇怪的，但是安装带有OpenCL支持的Tensorflow却不得不需要这个奇怪的库。首先你需要在其官网上注册一个账号来下载ComputeCPP，和牙膏厂一个尿性，然后解压后放到<code>/usr/lib</code>或者其他你能看得到的位置。</p>
<p>Tensorflow对于OpenCL的支持至今都是很有限的，所以你需要的是使用<strong>源码</strong>来安装Tensorflow而不是优雅的使用<code>pip3 install tensorflow-gpu</code>（都怪农企喜欢造挖矿卡）</p>
<p>直接参考Tensorflow的如何编译源码来安装就可以了。需要注意的是在enable Tensorflow support那块需要选择<strong>是</strong>，而CUDA那一块则要选择<strong>否</strong>。假设出现了要你选择OpenCL路径地方的时候，他显示的那个路径一般都是没有错的。所以这个时候你需要检查那个路径下是否生成了<code>libOpencl.so</code>这类型的文件。</p>
<p>这里就是英文的说明了：<a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="external">https://www.tensorflow.org/install/install_sources</a></p>
<h1 id="安装Keras"><a href="#安装Keras" class="headerlink" title="安装Keras"></a>安装Keras</h1><p>一句话 <code>pip3 install keras</code></p>
<h1 id="如何知道我是用了OpenCL"><a href="#如何知道我是用了OpenCL" class="headerlink" title="如何知道我是用了OpenCL"></a>如何知道我是用了OpenCL</h1><p>和使用CPU一般出现的TF让你编译TF到那些奇奇怪怪的（AXS是什么）格式，我的就会出现这种信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2017-07-07 20:35:24.377623: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices</div><div class="line">2017-07-07 20:35:24.378838: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0xaa19620 executing computations on platform Host. Devices:</div><div class="line">2017-07-07 20:35:24.378870: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;</div></pre></td></tr></table></figure>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>为了pip安装得快，你可以使用一些镜像库，比如中科大，淘宝以及清华tuna等的源。这里我比较推荐学生（比如边家村职业技术学院的少年）使用清华的源来避开锐捷的追杀。下面就是使用的方法：</p>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/pypi/" target="_blank" rel="external">https://mirrors.tuna.tsinghua.edu.cn/help/pypi/</a></p>
<p>然后Theano这块我怎么都没安装好，显示的是libgpuarray对我的显卡支持有限，反正错误我看不懂Orz。</p>
<p>最后祝各位电脑不要爆炸。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kidozh.github.io/2017/06/30/Header模板/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="kido zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kidozh">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/30/Header模板/" itemprop="url">Header模板</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-30T21:43:34+08:00">
                2017-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/未分类/" itemprop="url" rel="index">
                    <span itemprop="name">未分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>现在让我们开始创建主题把！</p>
<p>构建你的<code>header.php</code>并且使用HTML Doctype验证你的主题。在这个教程里可能会有大量的PHP代码，但是这一点也不重要。我们正要准备开始针对搜索引擎做一些优化，并且向<code>functions.php</code>文件之中添加一些东西。</p>
<p>这个教程假设你已经向你的header.php之中添加了一些基本的元素，如果你的header.php这个文件还是空的话，情查看之前的教程，再来一遍。</p>
<h1 id="头文件部分"><a href="#头文件部分" class="headerlink" title="头文件部分"></a>头文件部分</h1><p>现在你的空的WordPress主题在实际上来说是无用的。因为这是因为其缺失了<code>DocType</code>来指示浏览器如何编译HTML的造型。我们正要使用HTML5的<code>DocType</code>。HTML5现在能够很好的适用于我们的WordPress主题。</p>
<p>首先，打开<code>header.php</code>并且把下面的代码粘到里面。</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&lt;?php</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * The Header for our theme.</div><div class="line"> *</div><div class="line"> * Displays all of the &lt;head&gt; section and everything up till &lt;div id="main"&gt;</div><div class="line"> *</div><div class="line"> * <span class="doctag">@package</span> Shape</div><div class="line"> * <span class="doctag">@since</span> Shape 2.0</div><div class="line"> */</div><div class="line"><span class="meta">?&gt;</span>&lt;!DOCTYPE html&gt;</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="kido zhang" />
          <p class="site-author-name" itemprop="name">kido zhang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">112</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">78</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/kidozh" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/331837926Ji" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                    
                      Twitter
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/kidozh" target="_blank" title="weibo">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      weibo
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://douban.com/people/kidozh" target="_blank" title="douban">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      douban
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/people/kidozh" target="_blank" title="zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      zhihu
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2014 &mdash; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kido zhang</span>

  
</div>


  <div class="powered-by">
    由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
  </div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">
    主题 &mdash;
    <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
      NexT.Pisces
    </a>
  </div>


        







        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
