<!doctype html>
<html lang="en" xmlns:v-bind="http://www.w3.org/1999/xhtml">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <title>Digital Twins of Tool Wear by Deep Convolutional Generative Adversarial Network</title>
    <!-- customize css-->
    <link rel="stylesheet" href="./static/css/style.css">
</head>
<body>

<div class="container-fluid">
    <div class="row project-portal">
        <div class="col-md-10 offset-md-1 project-intro">
            <h1 class="text-center project-title">Digital Twins of Machining Tool</h1>
            <p class="text-center sub-title">By Deep Conditional Convolutional Generative Adversial Network</p>
            <p class="text-center"><a class="btn">Read Paper</a> <a href="https://github.com/kidozh/digital_twin_by_GAN" class="btn btn-inverse">Project &gt;</a> </p>
        </div>

    </div>
    <div class="row project-feature">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <h2 class="title">Unsupervised</h2>
                    <p class="paragraph">DCGAN is an advanced unsupervised approach to clone the distribution of real signal data.
                        Upsampling and Convolutional layer constitute transpose convolutional layer to generate hierarchy signal blueprint.
                        By competition between discriminator and generator, it's easy to re-create realistic signal.
                    </p>
                    <p class="paragraph">Since the data is obtained by unsupervised approach, the final result could be not stable.
                    In addition, because the optimization point is located at one saddle point of G-D tensor space, it make optimization
                        even harder.
                    </p>
                </div>
                <div class="col-md-4">
                    <h2 class="title">End-to-end Design</h2>
                    <p class="paragraph">
                        Key to simplify model's design is to using end-to-end architecture. The hybrid of generative and discriminative network
                        allows model to simplify both train and application process.
                    </p>
                    <p class="paragraph">
                        Fed with high-dimensional random noise, GAN can give diverse signal sample which is hard for machine to recognize validity.
                        By progressive deep-learning training, generative network is able to evolve itself. A remarkable signal could be obtained after
                        proper epoch of deep learning training.
                    </p>
                </div>
                <div class="col-md-4">
                    <h2 class="title">General</h2>
                    <p class="paragraph">
                        There is no requirement for distribution of original data. It enable the widespread use of GAN in general circumstances. The
                        only thing GAN need to do is clone the siblings of signal data. By introducing lantent space parameter(z), GAN can generate the
                        corresponding signal. It could help us to reinforce data, diagnose failure and optimize the best machining parameters by searching
                        z tensor space. It can be the fundamental ground research which enable network to handle realtime machining just like AlphaGo.
                    </p>
                </div>
            </div>

        </div>

    </div>
    <div class="row">
        <div class="container">
            <div class="row project-principle">
                <div class="col-md-12">
                    <h1 class="title">Co-evolution</h1>
                    <p>GAN training implements game theory that makes G and D network compete to exploit their performance.
                    Generative network(G) tries to generate realistic signal to deceive discriminative network(D). D tries to
                        identify the validity of given signal. Finally, both network achieve <strong>nash balance</strong> which means discriminator
                        fails to recognize signal and generator can give sequence whose data distribution is the same as original sample.
                    </p>
                    <h4 class="sub-title">Nash balance</h4>
                    <p>
                        Since the limit of sample's size and optimization's location, training of GAN is hard. Also, because range in every dimension is
                        different, the compound tensor may not be so accurate. But the tendency shows that GAN can clone data well.

                    </p>
                </div>
                <div class="col-md-12">
                    <p class="text-center"><img class="img-fluid" src="./static/images/gan_principle.svg"> </p>
                    <p class="text-center caption">The architecture of Generative Adversial Network(GAN) and digital twins' relation to it</p>
                </div>
            </div>

            <div class="row component">
                <div class="col-md-8">
                    <h1 class="title">Discriminative Network</h1>
                    <p>
                        The core of discriminator is classical post-activation design. By MLP architecture, discriminator can extract
                        features of machining signal at every abstract level.
                    </p>
                    <p>
                        The discriminator is fed with signal which may comes from real data and fake data generated by G-network. This
                        network will output a binary value recognizing validity of given sequence. Trained with Adam optimization
                        (learning rate 0.0001 and \( beta_1 \) 0.5), the discriminator will adapt itself to identify signal.
                    </p>
                    <h3 class="title">Loss function</h3>
                    <p>The loss function is binary crossentropy which is used for binary recognition.</p>
                    <p>
                        $$  loss = -\sum_{i=1}^{n}\hat{y_i}logy_i+(1-\hat{y_i})log(1-y_i)\\ \frac {\partial loss} {\partial y} = -\sum_{i=1}^{n}\frac {\hat{y_i}} {y_i}-\frac {1-\hat{y_i}} {1-y_i} $$
                    </p>

                    <h3 class="title">Technical Tricks</h3>
                    <p> In order to prevent sparse features, <strong>leaky rectified linear unit</strong>(LeakyRelu) activation is used.
                        In practical training of GAN, discriminator can always easily recognize whether given signal is true or fake. In order
                        to make competition stable, dropout layer with fair large dropout rate is applied. Because of prior success in monitoring
                        realtime tool wear, a descending dimension is implement in convolutional layer.
                    </p>

                </div>
                <div class="col-md-4">
                    <p class="text-center"><img class="img-fluid" src="./static/images/discriminative_network_architecture.svg"> </p>
                    <p class="caption text-center">The discriminator's architecture. (This architecture may change according to latest development
                        progress)</p>
                </div>
            </div>
            <div class="row component">

                <div class="col-md-8">
                    <h1 class="title">Generative Network</h1>
                    <p>
                        The core of generator is <strong><span class="upsampling">upsampling</span>-<span class="conv1d">convolutional</span></strong>
                        deconvolution structure. Upsampling enables signal to reshape and convolution allows information fusion at different time
                        of sequence. InstanceNormalization can better normalize features and avoid sparse characteristics in generative model.
                        LeakyRelu as the non-sparse activation function can reduce features' redundancy.
                    </p>
                    <p>
                        The generator is fed with signal which combined both noise(Usually <span class="text-success">Gaussian distribution</span>) and machining condition(need rescale method).
                        This network will yield a signal corresponding to given machining condition. Trained with Adam optimization (learning rate
                        0.0001 and \( beta_1 \) 0.5), the generator will adapt itself to produce signal according to machining condition.
                    </p>
                    <h3 class="title">Rescale method</h3>
                    <p>
                        For different machining condition, a separate rescaling method should be taken for better GAN training.
                    </p>
                    <ul class="machining-condition">
                        <li>
                            <h5 class="title">For discrete machining condition</h5>
                            <p>
                                For many machining condition, the change is not continuous. For example, machining tool type, workpiece material and
                                milling approach could all be considered discrete status. In this case, <b>embedding layer</b> should be taken into
                                use. This layer can implicitly indicates the relation among different status and decrease calculation cost. In
                                addition, if machining condition is complex and representing tensor is high dimensional, the sparse vector will increase
                                unnecessary cost and impede further immigration to new machining condition.
                            </p>
                            <p>
                                When network is trained, all embedding tensor will be updated. By calculating the similarity of different status,
                                many features could be reused to increase accuracy and generality. It's also helpful when later transfer learning
                                is applied.
                            </p>
                        </li>
                        <li>
                            <h5 class="title">For continuous machining condition</h5>
                            <p>
                                Continuous variables are also common in processing workpieces. For example, spindle speed, feed rate, machining temperature
                                and cut depth could set at any given figure. In this case, <b>full connected layer</b> should be used to rescale parameters.
                                In this layer, it can be simplified as a linear transformation \( y = a \times x + b \). If you know exact proper scaling
                                methods, it's better to directly transform the variable before training model.
                            </p>
                        </li>

                    </ul>
                    <p>Later, processed machining factor will be multiplied with rescale factor as the input of generator. This is the reason why
                        DCGAN is prefixed with <strong class="highlight-text">C</strong> which indicates conditional.
                    </p>
                    <h3 class="title">Technical tricks</h3>
                    <p>
                        The techniques applied in generative model are the same as discriminative one.
                    </p>
                </div>
                <div class="col-md-4">
                    <p class="text-center"><img class="img-fluid" src="./static/images/generative_network_architecture.svg"> </p>
                    <p class="text-center caption">
                        The generator's architecture(This architecture may change according to latest development progress).
                        <span class="text-danger">×</span> rounded by red dot means <span class="text-danger">multiply</span>
                        operation.
                    </p>
                </div>
            </div>
            <div class="row component">
                <div class="col-md-6">
                    <h1 class="title">Training Process</h1>
                    <p>The ideal mode of training is that G and D network compete to achieve nash balance. The best condition is
                     that accuracy of D is fluctuated around 50%. However, due to some reasons we have hardly known, D's accuracy is
                        unusual high which means D is very smart to recognize signal's validity. Even we increase dropout and G's
                        complexity, the phenomenon is still not apparent to see. But after exam generative signal with high-accurate ResNet,
                        the signal could be accepted in a way. Also, by observing final signal sample, it seems like experimental
                        signal.
                    </p>

                </div>
                <div class="col-md-6">
                    <p class="text-center"><img class="img-fluid" src="./static/images/loss_change_example.png"> </p>
                    <p class="text-center caption">
                        The training example of GAN. <span class="text-danger">The example is not related to this experiment!</span>
                    </p>
                </div>
            </div>
            <div class="row component">
                <div class="col-md-12">
                    <h1 class="title">Result</h1>
                    <h3 class="title">Pre-setup for evaluation</h3>
                    <p>
                        Because ResNet don't join GAN training, the evaluating result of Resnet could be regarded as convincing.
                        The ResNet fed with reinforced data can predict tool wear well according to machining signal.
                    </p>
                    <table class="table table-striped">
                        <thead>
                        <tr>
                            <th>MSE (Mean Square Error)</th>
                            <th>MAE (Mean Absolute Error)</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>0.630 (\( \mu m^2 \))</td>
                            <td>0.417 (\( \mu m^2 \))</td>
                        </tr>
                        </tbody>
                    </table>
                    <p class="text-center caption">
                        More detailed information about this Resnet, you can visit <a class="text-success" href="../">single machining monitor</a>  to
                        get more information
                    </p>
                    <h3 class="title">Evaluation</h3>
                    <p>
                        In the left figure, DCGAN can give corresponding signal by labels. Although there are many fluctuations
                        with expected label, the tendency still prove the validity of cloned signal. Also, this error may comes
                        from both evaluation error from Resnet and generative error from GAN.
                    </p>
                    <p>
                        In most condition, the evaluation follows expected tendency. In interval 25-75, the gan reacts a false
                        tendency, the most reason may be rescale problem. Also, that my GPU is too weak to train deep network
                        may be the reason why GAN sucks.
                    </p>
                    <p>
                        The initial GAN is not applied well in computer vision. But after two-year development, the deep fake and
                        other technology have proven the strength of GAN. I may start badly but truly hope gan could simualte signal
                        well one day.

                    </p>
                </div>
                <div class="col-md-12 result-figure-caption ">
                    <h3 class="text-center">Evaluation result of GAN after several epochs</h3>
                    <p class="text-center caption">
                        Due to my error, legend of this graph is not given. The <span class="text-danger">x-axis</span> is
                        <span class="text-danger">given tool wear</span> and <span class="text-danger">y-axis</span> is
                        <span class="text-danger">estimated value</span> examined by ResNet.
                    </p>
                </div>


                <div class="col-md-4">

                    <p class="text-center">
                        <img src="./static/images/DCGAN_57000_epoch.svg" class="img-fluid">
                    </p>
                    <p class="text-center caption">
                        The generated signal evaluated by ResNet after <span class="text-info">57000</span> epoch.
                    </p>
                </div>
                <div class="col-md-4">

                    <p class="text-center">
                        <img src="./static/images/DCGAN_62000_epoch.svg" class="img-fluid">
                    </p>
                    <p class="text-center caption">
                        The generated signal evaluated by ResNet after <span class="text-info">62000</span> epoch.
                    </p>
                </div>
                <div class="col-md-4">

                    <p class="text-center">
                        <img src="./static/images/DCGAN_148000_epoch.svg" class="img-fluid">
                    </p>
                    <p class="text-center caption">
                        The generated signal evaluated by ResNet after <span class="text-info">148000</span> epoch.
                    </p>
                </div>

            </div>
            <div class="row component" id="gan-demo">
                <div class="col-md-12">
                    <h1 class="title text-center">Generated signal sample at different tool status</h1>
                    <p class="text-center">
                        The following graph shows the generated signal in given tool wear label. Feel free to explore,
                        you can't break it, we promise.

                    </p>
                    <div class="row">
                        <div class="col-md-6 offset-md-3">
                            <p>Select GAN's performance at given epoch</p>
                            <select v-model="current_epoch" class="form-control" >
                                <option v-for="epoch in epoch_list">{{epoch}}</option>
                            </select>
                        </div>
                    </div>
                </div>
                <div class="col-md-12">
                    <p class="text-center">
                        <img class="img-fluid" v-bind:src="evaluate_image_path">
                    </p>
                    <p class="caption text-center">
                        Train evaluation at epoch <span class="text-danger">{{current_epoch}}</span>
                    </p>
                </div>
                <div class="col-md-12" v-show="have_dimension_pic">
                    <h3 class="text-center">
                        Each channel of signal on epoch <span class="text-danger">{{current_epoch}}</span>
                    </h3>
                </div>
                <div class="col-md-10 offset-md-1" v-show="! have_dimension_pic">
                    <p class="text-center">Sorry, we can't provide dimensional data , since we only store dimensional
                        sample every 2000 epoch.
                        your selection, <span class="text-danger">{{current_epoch}}</span>, doesn't
                        fit this regulation.
                    </p>
                </div>
                <div class="col-md-4" v-for="data in images_path" v-show="have_dimension_pic">
                    <p class="text-center">
                        <img class="img-fluid" v-bind:src="data.path">

                    </p>
                    <p class="caption text-center">{{data.caption}}</p>
                </div>
            </div>

        </div>

    </div>
    <div class="row conclusion-section">
        <div class="col-md-8 offset-md-1">
            <h3 class="conclusion">
                Given that more than 40000+ reinforced data, tool wear digital twins by GAN can clone machining signal and
                be compatible with tool wear tendency. Furthermore, we hope that this technology can promote itself to achieve
                higher accuracy. Then, this digital twins could be the reference when we can search this model to simulate real
                machining process in data science way.
            </h3>
        </div>
    </div>
    <div class="row contact-section">
        <div class="col-md-10 offset-md-1">
            <h3 class="contact">If you have questions about our work, contact us at: kidozh@gmail.com</h3>
        </div>
    </div>

    <div class="row footer">
        <div class="col-md-12">
            <h3 class="text-center">This project is licensed <a href="https://github.com/kidozh/keras_detect_tool_wear/blob/master/LICENSE">MIT</a>,
                Docs <a href="https://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>
            </h3>
        </div>

    </div>

</div>


<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
<!-- mathjax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>

<script>
    var vm = new Vue({
        el: '#gan-demo',
        data:{
            current_epoch:148000,
        },
        computed:{
            images_path:function () {
                // add evaluation first
                var current_epoch_string = this.current_epoch.toString();
                var path_prefix = "./static/images/samples_and_evaluation/";
                // var evaluation_name = "DCGAN_"+current_epoch_string+"_epoch.svg";
                var image_path_list = [];
                //image_path_list.push(path_prefix+evaluation_name);
                for(let i=1; i<8; i++){
                    var caption_str = "";
                    var three_dimension_name_list = ["X","Y","Z"]
                    if(i <= 3){
                        caption_str = "Force (N) in " + three_dimension_name_list[(i-1)%3] + " dimension";
                    }
                    else if(i <= 6){
                        caption_str = "Vibration (g) in " + three_dimension_name_list[(i-1)%3] + " dimension";
                    }
                    else{
                        caption_str = "Acoustic Emission / AE-RMS (V)"
                    }

                    var channel_path = i.toString()+"/"+"channel_"+i.toString()+"_epoch_"+current_epoch_string+".png";
                    var data = {
                        path : path_prefix + channel_path,
                        caption: caption_str
                    };
                    image_path_list.push(data);
                }
                return image_path_list;
            },
            evaluate_image_path:function () {
                var current_epoch_string = this.current_epoch.toString();
                var path_prefix = "./static/images/samples_and_evaluation/";
                var evaluation_name = "DCGAN_"+current_epoch_string+"_epoch.svg";
                return path_prefix+evaluation_name
            },
            have_dimension_pic:function () {
                if(this.current_epoch % 2000 === 0) return true;
                return false;
            },
            epoch_list :function () {
                var epoch_list = [];
                for(var i = 0; i<= 170000 ; i+= 1000 ){

                    epoch_list.push(i);
                }
                return epoch_list;
            }
        }
    });

</script>

</body>
</html>